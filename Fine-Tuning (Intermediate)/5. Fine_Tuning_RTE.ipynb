{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df99fe5-8cf2-4d00-95bb-1feb89344182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658053ad-49bf-427a-8b6a-e4527df2c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/rte to C:/Users/sthor/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 697k/697k [00:01<00:00, 647kB/s]  \n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to C:/Users/sthor/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 170.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# The Recognizing Textual Entailment (RTE) datasets come from a series of annual\n",
    "# textual entailment challenges. We combine the data from RTE1 (Dagan et al.,\n",
    "# 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5\n",
    "# (Bentivogli et al., 2009).4 Examples are constructed based on news and\n",
    "# Wikipedia text. We convert all datasets to a two-class split, where for\n",
    "# three-class datasets we collapse neutral and contradiction into not\n",
    "# entailment, for consistency.\n",
    "raw_datasets = load_dataset(\"glue\", \"rte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c8d697-c553-4b88-aba6-1f1e866e98e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 2490\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 277\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a47e020-83ad-45b4-91b3-ea901ee1ca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['entailment', 'not_entailment'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ae911d-effd-4a15-b6dc-ae02384d7bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No Weapons of Mass Destruction Found in Iraq Yet.',\n",
       " 'A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI.',\n",
       " 'Herceptin was already approved to treat the sickest breast cancer patients, and the company said, Monday, it will discuss with federal regulators the possibility of prescribing the drug for more breast cancer patients.',\n",
       " 'Judie Vivian, chief executive at ProMedica, a medical service company that helps sustain the 2-year-old Vietnam Heart Institute in Ho Chi Minh City (formerly Saigon), said that so far about 1,500 children have received treatment.',\n",
       " \"A man is due in court later charged with the murder 26 years ago of a teenager whose case was the first to be featured on BBC One's Crimewatch. Colette Aram, 16, was walking to her boyfriend's house in Keyworth, Nottinghamshire, on 30 October 1983 when she disappeared. Her body was later found in a field close to her home. Paul Stewart Hutchinson, 50, has been charged with murder and is due before Nottingham magistrates later.\",\n",
       " 'Britain said, Friday, that it has barred cleric, Omar Bakri, from returning to the country from Lebanon, where he was released by police after being detained for 24 hours.',\n",
       " \"Nearly 4 million children who have at least one parent who entered the U.S. illegally were born in the United States and are U.S. citizens as a result, according to the study conducted by the Pew Hispanic Center. That's about three quarters of the estimated 5.5 million children of illegal immigrants inside the United States, according to the study. About 1.8 million children of undocumented immigrants live in poverty, the study found.\",\n",
       " 'Like the United States, U.N. officials are also dismayed that Aristide killed a conference called by Prime Minister Robert Malval in Port-au-Prince in hopes of bringing all the feuding parties together.',\n",
       " \"WASHINGTON --  A newly declassified narrative of the Bush administration's advice to the CIA on harsh interrogations shows that the small group of Justice Department lawyers who wrote memos authorizing controversial interrogation techniques were operating not on their own but with direction from top administration officials, including then-Vice President Dick Cheney and national security adviser Condoleezza Rice. At the same time, the narrative suggests that then-Defense Secretary Donald H. Rumsfeld and then-Secretary of State Colin Powell were largely left out of the decision-making process.\",\n",
       " 'Only a week after it had no comment on upping the storage capacity of its Hotmail e-mail service, Microsoft early Thursday announced it was boosting the allowance to 250MB to follow similar moves by rivals such as Google, Yahoo, and Lycos.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['sentence1'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b41363-463a-49fd-85f4-1be24137723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-cased'\n",
    "# checkpoint = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156abbe2-2f68-492b-8a9d-3ca8fe299b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "  Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "434f70aa-2871-48c7-8b77-370901bb9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f08a963-00af-4be8-8881-4b66711671d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1302, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 6355, 119, 102, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\n",
    "    raw_datasets['train']['sentence1'][0],\n",
    "    raw_datasets['train']['sentence2'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9adf55e-122d-4f7e-a99e-b3551e76ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd6589f4-d202-4bdd-bd32-e22edb532383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distilbert doesn't use token_type_ids\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be40624-5a10-4fd4-ac07-8a80e054b8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] No Weapons of Mass Destruction Found in Iraq Yet. [SEP] Weapons of Mass Destruction Found in Iraq. [SEP]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(result['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1146d3b-6ced-4601-802b-66ba5adf1a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc35c725-9993-4e52-b2a8-79f0106977c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir='training_dir',\n",
    "  evaluation_strategy='epoch',\n",
    "  save_strategy='epoch',\n",
    "  num_train_epochs=5,\n",
    "  per_device_train_batch_size=16,\n",
    "  per_device_eval_batch_size=64,\n",
    "  logging_steps=150, # otherwise, 'no log' will appear under training loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4cebfbd-31c6-485b-aa31-0e2ccacca4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "466cdf14-4432-407d-bc12-fca14f824da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\AppData\\Local\\Temp\\ipykernel_13008\\242969656.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"glue\", \"rte\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"glue\", \"rte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45ceff7a-69cb-48bf-8216-2d5779eb4c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=[1, 0, 1], references=[1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "742b8314-8e6b-4ef5-8373-1eaddf3a8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31731992-416c-4bfe-b93e-122e3d1c9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "  logits, labels = logits_and_labels\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  acc = np.mean(predictions == labels)\n",
    "  f1 = f1_score(labels, predictions)\n",
    "  return {'accuracy': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f859ecf-2cfb-4955-9954-d64964828949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "  return tokenizer(batch['sentence1'], batch['sentence2'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eee0c5e2-e319-4ad0-82bd-c90dca023dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b47d361-4552-48c8-a216-517a0d766713",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a39fd94f-693f-4fe8-b845-ec0f652027af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [780/780 01:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.697200</td>\n",
       "      <td>0.712245</td>\n",
       "      <td>0.472924</td>\n",
       "      <td>0.642157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.678400</td>\n",
       "      <td>0.701237</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.374384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.890898</td>\n",
       "      <td>0.523466</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>1.446186</td>\n",
       "      <td>0.501805</td>\n",
       "      <td>0.527397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>1.946322</td>\n",
       "      <td>0.519856</td>\n",
       "      <td>0.509225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=780, training_loss=0.4461210605425712, metrics={'train_runtime': 110.5302, 'train_samples_per_second': 112.639, 'train_steps_per_second': 7.057, 'total_flos': 543568586467824.0, 'train_loss': 0.4461210605425712, 'epoch': 5.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "928440c9-60c1-495b-bea8-9e7a022e00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilbert train_steps_per_second': 1.91\n",
    "# bert 'train_steps_per_second': 1.042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26d8f386-7b64-4469-9430-3cfe84491a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b5975e-fb64-48cb-87df-cd003b68c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "p = pipeline('text-classification', model='my_saved_model', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "599861e7-dd5f-4a91-aaa5-d0bbaac2e6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'LABEL_0', 'score': 0.9638515114784241}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p({'text': 'I went to the store', 'text_pair': 'I am a bird'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4f64d-f402-498b-aec8-e56332666585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
