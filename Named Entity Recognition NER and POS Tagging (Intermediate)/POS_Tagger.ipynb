{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5284f8-6d51-4f86-84ca-85aa678b5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a01f8078-0ba0-49a7-96cb-e2c15a347ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\sthor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\sthor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d472f7f7-747e-4a90-8627-7930ac3ac0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = brown.tagged_sents(tagset='universal')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34a13cbd-a55e-487f-bd47-a9776770f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for sentence_tag_pairs in corpus:\n",
    "    tokens = []\n",
    "    target = []\n",
    "    for token, tag in sentence_tag_pairs:\n",
    "        tokens.append(token)\n",
    "        target.append(tag)\n",
    "    inputs.append(tokens)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96723e89-3819-4cdb-9f81-9b700f29187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to json format\n",
    "import json\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    for x, y in zip(inputs, targets):\n",
    "        j = {'inputs': x, 'targets': y}\n",
    "        s = json.dumps(j)\n",
    "        f.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0a032c1-4327-4392-8bff-4974a0b18963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1db8ae3-184f-4dfa-93b8-55a421555841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:/Users/sthor/.cache/huggingface/datasets/json/default-40e085596c056f43/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/sthor/.cache/huggingface/datasets/json/default-40e085596c056f43/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 333.25it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e073e7b4-7c83-47fd-89f1-b56aaa29d817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 57340\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "164eaca5-4196-4df5-80c0-0cd9b9091951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'targets'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = data[\"train\"].shuffle(seed=42).select(range(20_000))\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d590f4a-7091-4eaa-954e-1435d701cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = small.train_test_split(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0266f50d-8a1b-4b7a-88c9-4204a3849d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': ['Ulyate',\n",
       "  'and',\n",
       "  'Kearton',\n",
       "  'climbed',\n",
       "  'on',\n",
       "  'toward',\n",
       "  'the',\n",
       "  'sound',\n",
       "  'of',\n",
       "  'the',\n",
       "  'barking',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dogs',\n",
       "  'and',\n",
       "  'the',\n",
       "  'sporadic',\n",
       "  'roaring',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lion',\n",
       "  ',',\n",
       "  'till',\n",
       "  'they',\n",
       "  'came',\n",
       "  ',',\n",
       "  'out',\n",
       "  'of',\n",
       "  'breath',\n",
       "  ',',\n",
       "  'to',\n",
       "  'the',\n",
       "  'crest',\n",
       "  ',',\n",
       "  'and',\n",
       "  'peering',\n",
       "  'through',\n",
       "  'the',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'a',\n",
       "  'bush',\n",
       "  ',',\n",
       "  'this',\n",
       "  'is',\n",
       "  'what',\n",
       "  'Ulyate',\n",
       "  'saw',\n",
       "  ':',\n",
       "  'Jones',\n",
       "  'who',\n",
       "  'had',\n",
       "  'apparently',\n",
       "  '(',\n",
       "  'and',\n",
       "  'actually',\n",
       "  'had',\n",
       "  ')',\n",
       "  'ridden',\n",
       "  'up',\n",
       "  'the',\n",
       "  'nearly',\n",
       "  'impassable',\n",
       "  'hillside',\n",
       "  ',',\n",
       "  'sitting',\n",
       "  'calmly',\n",
       "  'on',\n",
       "  'his',\n",
       "  'horse',\n",
       "  'within',\n",
       "  'forty',\n",
       "  'feet',\n",
       "  'of',\n",
       "  'a',\n",
       "  'full-grown',\n",
       "  'young',\n",
       "  'lioness',\n",
       "  ',',\n",
       "  'who',\n",
       "  'was',\n",
       "  'crouched',\n",
       "  'on',\n",
       "  'a',\n",
       "  'flat',\n",
       "  'rock',\n",
       "  'and',\n",
       "  'seemed',\n",
       "  'just',\n",
       "  'about',\n",
       "  'to',\n",
       "  'charge',\n",
       "  'him',\n",
       "  ',',\n",
       "  'while',\n",
       "  'the',\n",
       "  'dogs',\n",
       "  'whirled',\n",
       "  'around',\n",
       "  'her',\n",
       "  '.'],\n",
       " 'targets': ['NOUN',\n",
       "  'CONJ',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'PRT',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'CONJ',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'ADP',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  '.',\n",
       "  'PRT',\n",
       "  'ADP',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'CONJ',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'DET',\n",
       "  'VERB',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  '.',\n",
       "  'NOUN',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'ADV',\n",
       "  '.',\n",
       "  'CONJ',\n",
       "  'ADV',\n",
       "  'VERB',\n",
       "  '.',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADV',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'VERB',\n",
       "  'ADV',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'NUM',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'CONJ',\n",
       "  'VERB',\n",
       "  'ADV',\n",
       "  'ADV',\n",
       "  'PRT',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  '.',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'PRON',\n",
       "  '.']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be7e7172-2a99-4e00-9901-00abd4e94c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'targets': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b77373d5-9ede-4733-b5c7-e14419a26038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map targets to ints\n",
    "target_set = set()\n",
    "for target in targets:\n",
    "    target_set = target_set.union(target)\n",
    "target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c111f6c-9fb7-4727-83a0-fc5cac92150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "046ab15f-8370-4e89-a849-dfe02d9972c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = [subitem for item in targets for subitem in item]\n",
    "target_set = set(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6308736a-2035-41c2-b2b7-01074c19dc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fcdb36a2-34eb-4f9b-a2e3-0af9e7301667",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = list(target_set)\n",
    "id2label = {k: v for k, v in enumerate(target_list)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f19a347-1069-463a-8cae-3d34d0ccc398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'DET',\n",
       " 1: 'PRT',\n",
       " 2: '.',\n",
       " 3: 'VERB',\n",
       " 4: 'NOUN',\n",
       " 5: 'X',\n",
       " 6: 'ADJ',\n",
       " 7: 'PRON',\n",
       " 8: 'CONJ',\n",
       " 9: 'ADV',\n",
       " 10: 'ADP',\n",
       " 11: 'NUM'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c59d5c1-c7d3-4d80-b166-d4dd62dad962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DET': 0,\n",
       " 'PRT': 1,\n",
       " '.': 2,\n",
       " 'VERB': 3,\n",
       " 'NOUN': 4,\n",
       " 'X': 5,\n",
       " 'ADJ': 6,\n",
       " 'PRON': 7,\n",
       " 'CONJ': 8,\n",
       " 'ADV': 9,\n",
       " 'ADP': 10,\n",
       " 'NUM': 11}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0db9e42d-6744-4292-8ebd-72f2c4310d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# also try using bert\n",
    "checkpoint = \"distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3261fe54-7f44-418f-993c-bebdd2044710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 158, 25928, 1566, 1105, 26835, 9349, 1320, 5998, 1113, 1755, 1103, 1839, 1104, 1103, 26635, 1104, 1103, 6363, 1105, 1103, 188, 27695, 23041, 1104, 1103, 11160, 117, 6174, 1152, 1338, 117, 1149, 1104, 2184, 117, 1106, 1103, 13468, 117, 1105, 19205, 1194, 1103, 5020, 1104, 170, 13771, 117, 1142, 1110, 1184, 158, 25928, 1566, 1486, 131, 2690, 1150, 1125, 4547, 113, 1105, 2140, 1125, 114, 17698, 1146, 1103, 2212, 24034, 11192, 1895, 25068, 117, 2807, 13285, 1113, 1117, 3241, 1439, 5808, 1623, 1104, 170, 1554, 118, 4215, 1685, 11160, 5800, 117, 1150, 1108, 15062, 1113, 170, 3596, 2067, 1105, 1882, 1198, 1164, 1106, 2965, 1140, 117, 1229, 1103, 6363, 18370, 1213, 1123, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "t = tokenizer(data[\"train\"][idx][\"inputs\"], is_split_into_words=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93c8fb28-327c-4676-a3ab-a7a967de77c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3da3579-59ba-4c5a-8426-dea42d3aa379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'U',\n",
       " '##lya',\n",
       " '##te',\n",
       " 'and',\n",
       " 'Ke',\n",
       " '##art',\n",
       " '##on',\n",
       " 'climbed',\n",
       " 'on',\n",
       " 'toward',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'of',\n",
       " 'the',\n",
       " 'barking',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dogs',\n",
       " 'and',\n",
       " 'the',\n",
       " 's',\n",
       " '##poradic',\n",
       " 'roaring',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lion',\n",
       " ',',\n",
       " 'till',\n",
       " 'they',\n",
       " 'came',\n",
       " ',',\n",
       " 'out',\n",
       " 'of',\n",
       " 'breath',\n",
       " ',',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crest',\n",
       " ',',\n",
       " 'and',\n",
       " 'peering',\n",
       " 'through',\n",
       " 'the',\n",
       " 'branches',\n",
       " 'of',\n",
       " 'a',\n",
       " 'bush',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'what',\n",
       " 'U',\n",
       " '##lya',\n",
       " '##te',\n",
       " 'saw',\n",
       " ':',\n",
       " 'Jones',\n",
       " 'who',\n",
       " 'had',\n",
       " 'apparently',\n",
       " '(',\n",
       " 'and',\n",
       " 'actually',\n",
       " 'had',\n",
       " ')',\n",
       " 'ridden',\n",
       " 'up',\n",
       " 'the',\n",
       " 'nearly',\n",
       " 'imp',\n",
       " '##ass',\n",
       " '##able',\n",
       " 'hillside',\n",
       " ',',\n",
       " 'sitting',\n",
       " 'calmly',\n",
       " 'on',\n",
       " 'his',\n",
       " 'horse',\n",
       " 'within',\n",
       " 'forty',\n",
       " 'feet',\n",
       " 'of',\n",
       " 'a',\n",
       " 'full',\n",
       " '-',\n",
       " 'grown',\n",
       " 'young',\n",
       " 'lion',\n",
       " '##ess',\n",
       " ',',\n",
       " 'who',\n",
       " 'was',\n",
       " 'crouched',\n",
       " 'on',\n",
       " 'a',\n",
       " 'flat',\n",
       " 'rock',\n",
       " 'and',\n",
       " 'seemed',\n",
       " 'just',\n",
       " 'about',\n",
       " 'to',\n",
       " 'charge',\n",
       " 'him',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'dogs',\n",
       " 'whirled',\n",
       " 'around',\n",
       " 'her',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7304a9a-d611-4877-8801-1e7b738e8c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 75,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " None]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f436778-89e5-4aeb-89d5-f00e8d3ed817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_targets(labels, word_ids):\n",
    "    aligned_labels = []\n",
    "    for word in word_ids:\n",
    "        if word is None:\n",
    "            # it's a token like [CLS]\n",
    "            label = -100\n",
    "        else:\n",
    "            # it's a real word\n",
    "            label = label2id[labels[word]]\n",
    "            \n",
    "        # add the label\n",
    "        aligned_labels.append(label)\n",
    "    \n",
    "    return aligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3556176a-1824-4873-87c7-8f9a1e533d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 10,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 11,\n",
       " 4,\n",
       " 10,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 10,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " -100]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try our function\n",
    "labels = data[\"train\"][idx][\"targets\"]\n",
    "word_ids = t.word_ids()\n",
    "aligned_targets = align_targets(labels, word_ids)\n",
    "aligned_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7658113d-0245-4cdc-b8d9-de32b6a6280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\tNone\n",
      "U\tNOUN\n",
      "##lya\tNOUN\n",
      "##te\tNOUN\n",
      "and\tCONJ\n",
      "Ke\tNOUN\n",
      "##art\tNOUN\n",
      "##on\tNOUN\n",
      "climbed\tVERB\n",
      "on\tPRT\n",
      "toward\tADP\n",
      "the\tDET\n",
      "sound\tNOUN\n",
      "of\tADP\n",
      "the\tDET\n",
      "barking\tNOUN\n",
      "of\tADP\n",
      "the\tDET\n",
      "dogs\tNOUN\n",
      "and\tCONJ\n",
      "the\tDET\n",
      "s\tADJ\n",
      "##poradic\tADJ\n",
      "roaring\tNOUN\n",
      "of\tADP\n",
      "the\tDET\n",
      "lion\tNOUN\n",
      ",\t.\n",
      "till\tADP\n",
      "they\tPRON\n",
      "came\tVERB\n",
      ",\t.\n",
      "out\tPRT\n",
      "of\tADP\n",
      "breath\tNOUN\n",
      ",\t.\n",
      "to\tADP\n",
      "the\tDET\n",
      "crest\tNOUN\n",
      ",\t.\n",
      "and\tCONJ\n",
      "peering\tVERB\n",
      "through\tADP\n",
      "the\tDET\n",
      "branches\tNOUN\n",
      "of\tADP\n",
      "a\tDET\n",
      "bush\tNOUN\n",
      ",\t.\n",
      "this\tDET\n",
      "is\tVERB\n",
      "what\tDET\n",
      "U\tNOUN\n",
      "##lya\tNOUN\n",
      "##te\tNOUN\n",
      "saw\tVERB\n",
      ":\t.\n",
      "Jones\tNOUN\n",
      "who\tPRON\n",
      "had\tVERB\n",
      "apparently\tADV\n",
      "(\t.\n",
      "and\tCONJ\n",
      "actually\tADV\n",
      "had\tVERB\n",
      ")\t.\n",
      "ridden\tVERB\n",
      "up\tADP\n",
      "the\tDET\n",
      "nearly\tADV\n",
      "imp\tADJ\n",
      "##ass\tADJ\n",
      "##able\tADJ\n",
      "hillside\tNOUN\n",
      ",\t.\n",
      "sitting\tVERB\n",
      "calmly\tADV\n",
      "on\tADP\n",
      "his\tDET\n",
      "horse\tNOUN\n",
      "within\tADP\n",
      "forty\tNUM\n",
      "feet\tNOUN\n",
      "of\tADP\n",
      "a\tDET\n",
      "full\tADJ\n",
      "-\tADJ\n",
      "grown\tADJ\n",
      "young\tADJ\n",
      "lion\tNOUN\n",
      "##ess\tNOUN\n",
      ",\t.\n",
      "who\tPRON\n",
      "was\tVERB\n",
      "crouched\tVERB\n",
      "on\tADP\n",
      "a\tDET\n",
      "flat\tADJ\n",
      "rock\tNOUN\n",
      "and\tCONJ\n",
      "seemed\tVERB\n",
      "just\tADV\n",
      "about\tADV\n",
      "to\tPRT\n",
      "charge\tVERB\n",
      "him\tPRON\n",
      ",\t.\n",
      "while\tADP\n",
      "the\tDET\n",
      "dogs\tNOUN\n",
      "whirled\tVERB\n",
      "around\tADP\n",
      "her\tPRON\n",
      ".\t.\n",
      "[SEP]\tNone\n"
     ]
    }
   ],
   "source": [
    "aligned_labels = [id2label[i] if i >= 0 else None for i in aligned_targets]\n",
    "for x, y in zip(t.tokens(), aligned_labels):\n",
    "    print(f\"{x}\\t{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e05d709-f827-4fac-94f9-4d81007d05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize both inputs and targets\n",
    "def tokenize_fn(batch):\n",
    "    # tokenize the input sequence first\n",
    "    # this populates inputs_ids, attention_mask, etc\n",
    "    tokenized_inputs = tokenizer(\n",
    "        batch['inputs'], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    \n",
    "    labels_batch = batch['targets'] # original targets\n",
    "    aligned_labels_batch = []\n",
    "    for i, labels in enumerate(labels_batch):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        aligned_labels_batch.append(align_targets(labels, word_ids))\n",
    "        \n",
    "    # recall: the 'target' numst be stored in key called 'labels'\n",
    "    tokenized_inputs['labels'] = aligned_labels_batch\n",
    "    \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f386a9e2-11b1-4cf2-aeef-34bae8e7f506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputs', 'targets']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# want to remove these from model inputs - they are neither inputs nor targets\n",
    "data[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d6a0fad-f809-46f7-b7ed-08a8bd347ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = data.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=data[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cdf43908-1188-471b-ab8d-78024015dfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 15000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8fe1fb67-e0cc-4af5-acc0-ffe47fea2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3cc7b321-4f3c-4b8e-bd47-66383efed53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/11264684/flatten-list-of-lists\n",
    "def flatten(list_of_lists):\n",
    "  flattened = [val for sublist in list_of_lists for val in sublist]\n",
    "  return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98f49a57-bbf1-4e72-a9cc-0fa5c128145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # remove -100 from labels and predictions\n",
    "    labels_jagged = [[t for t in label if t != -100] for label in labels]\n",
    "    \n",
    "    # do the same for predictions whenever true label is -100\n",
    "    preds_jagged = [[p for p, t in zip(ps, ts) if t != -100] for ps, ts in zip(preds, labels)]\n",
    "    \n",
    "    # flatten labels and preds\n",
    "    labels_flat = flatten(labels_jagged)\n",
    "    preds_flat = flatten(preds_jagged)\n",
    "    \n",
    "    acc = accuracy_score(labels_flat, preds_flat)\n",
    "    f1 = f1_score(labels_flat, preds_flat, average = 'macro')\n",
    "    \n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b9e7b78f-edfc-4392-bf99-48a30ddc9af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6, 'accuracy': 0.8}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [[-100, 0, 0, 1, 2, 1, -100]]\n",
    "logits = np.array([[\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "]])\n",
    "compute_metrics((logits, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da401d21-c0ba-4cee-b1e6-1ef9a5a31084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88bc00f9-fecb-476e-b110-d1ddf00b2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"distilbert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "339fb400-4599-47f7-8a5f-d16884aacb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 02:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056578</td>\n",
       "      <td>0.942661</td>\n",
       "      <td>0.983344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.054017</td>\n",
       "      <td>0.953740</td>\n",
       "      <td>0.985293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.06818035519917806, metrics={'train_runtime': 163.4611, 'train_samples_per_second': 183.53, 'train_steps_per_second': 22.941, 'total_flos': 386431490254464.0, 'train_loss': 0.06818035519917806, 'epoch': 2.0})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset= tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89da9aaa-27d8-40cd-ad84-10018f1819af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "777f267c-93b5-4ef5-9ffd-60bfcb491ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=\"my_saved_model\",\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ba155fd-e8be-44e1-8a3c-32b0f4a3c8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'NOUN',\n",
       "  'score': 0.99966323,\n",
       "  'index': 1,\n",
       "  'word': 'Bill',\n",
       "  'start': 0,\n",
       "  'end': 4},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.99973255,\n",
       "  'index': 2,\n",
       "  'word': 'Gates',\n",
       "  'start': 5,\n",
       "  'end': 10},\n",
       " {'entity': 'VERB',\n",
       "  'score': 0.9998468,\n",
       "  'index': 3,\n",
       "  'word': 'was',\n",
       "  'start': 11,\n",
       "  'end': 14},\n",
       " {'entity': 'DET',\n",
       "  'score': 0.99985135,\n",
       "  'index': 4,\n",
       "  'word': 'the',\n",
       "  'start': 15,\n",
       "  'end': 18},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.99974555,\n",
       "  'index': 5,\n",
       "  'word': 'CEO',\n",
       "  'start': 19,\n",
       "  'end': 22},\n",
       " {'entity': 'ADP',\n",
       "  'score': 0.99980253,\n",
       "  'index': 6,\n",
       "  'word': 'of',\n",
       "  'start': 23,\n",
       "  'end': 25},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.99968696,\n",
       "  'index': 7,\n",
       "  'word': 'Microsoft',\n",
       "  'start': 26,\n",
       "  'end': 35},\n",
       " {'entity': 'ADP',\n",
       "  'score': 0.9997876,\n",
       "  'index': 8,\n",
       "  'word': 'in',\n",
       "  'start': 36,\n",
       "  'end': 38},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9998294,\n",
       "  'index': 9,\n",
       "  'word': 'Seattle',\n",
       "  'start': 39,\n",
       "  'end': 46},\n",
       " {'entity': '.',\n",
       "  'score': 0.9998547,\n",
       "  'index': 10,\n",
       "  'word': ',',\n",
       "  'start': 46,\n",
       "  'end': 47},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9998048,\n",
       "  'index': 11,\n",
       "  'word': 'Washington',\n",
       "  'start': 48,\n",
       "  'end': 58},\n",
       " {'entity': '.',\n",
       "  'score': 0.9998406,\n",
       "  'index': 12,\n",
       "  'word': '.',\n",
       "  'start': 58,\n",
       "  'end': 59}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Bill Gates was the CEO of Microsoft in Seattle, Washington.\"\n",
    "pipe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41728807-7b73-47ae-9b00-21dab86de8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
