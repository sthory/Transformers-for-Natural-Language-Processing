{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9928feae-b153-44af-832e-a4f6db11944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/sthor/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00, 166.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"squad\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08289ed7-0d05-4613-8bab-b81e3f315947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'University_of_Notre_Dame'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][1][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad764488-2b74-4afe-b9dc-1aa30237f15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][1][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a803af98-0579-4337-9d59-f3ec84d28400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is in front of the Notre Dame Main Building?'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][1][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f219e789-c09e-48cb-b73a-68d7d1f55100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][1][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0540b253-2999-4e20-8204-dd9407ca9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sthor\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-0c357a91ac1d3bad.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for train set, ensure that there's always 1 answer\n",
    "# not multiple answers, or no answers\n",
    "raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c6b2cfad-f3b1-433a-b719-2bb481414595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Santa Clara, California',\n",
       "  \"Levi's Stadium\",\n",
       "  \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
       " 'answer_start': [403, 355, 355]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for validation set, there may be multiple answers\n",
    "raw_datasets[\"validation\"][2][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eec72a90-37e4-4b29-949a-71daf32f629b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why are there multiple answers?\n",
    "raw_datasets[\"validation\"][2][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68e5040a-e6d1-43fc-9a47-07f110dc48ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where did Super Bowl 50 take place?'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"validation\"][2][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c46577a-f6e9-4b76-a62f-ab33da9a0887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       " 'answer_start': [177, 177, 177]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# they may even be the same!\n",
    "raw_datasets[\"validation\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "25da19ed-b264-4834-a790-973adeac915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 14.5kB/s]\n",
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sthor\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 195kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 833kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 3.74MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#model_checkpoint = \"distilbert-base-cased\"\n",
    "model_checkpoint = \"bert-base-cased\" # try it yourself\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23e19a6b-8af9-4915-834c-7ac99a20b1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = raw_datasets[\"train\"][1][\"context\"]\n",
    "question = raw_datasets[\"train\"][1][\"question\"]\n",
    "\n",
    "inputs = tokenizer(question, context)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbdc0181-7380-4844-94aa-0c75415fec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304] \n",
      "\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# what if the context is really long?\n",
    "# split it into multiple samples\n",
    "inputs = tokenizer(\n",
    "  question,\n",
    "  context,\n",
    "  max_length=100,\n",
    "  truncation=\"only_second\",\n",
    "  stride=50,\n",
    "  return_overflowing_tokens=True,\n",
    ")\n",
    "\n",
    "print(inputs[\"input_ids\"][0][0:10], \"\\n\")\n",
    "\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "  print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c73fe36c-f8f0-4113-9c20-f838dca2b53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f03d199-0f12-4029-91f6-9ba69acf25d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's the new key?\n",
    "inputs['overflow_to_sample_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f44dcadc-9acc-4df0-b904-e324896ea80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:3][\"question\"],\n",
    "    raw_datasets[\"train\"][:3][\"context\"],\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "inputs['overflow_to_sample_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "437d5a79-e34c-4154-9486-1f99c11942dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n",
      "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n",
      "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n",
      "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n",
      "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n",
      "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n",
      "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n",
      "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# it points to the original sample index\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "  print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "047af2b1-99d5-40c4-ba58-4542560446e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recreate inputs for just a single context-question pair\n",
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8129e2ae-9762-4c78-a4e4-0def5896a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (0, 13),\n",
       "  (13, 15),\n",
       "  (15, 16),\n",
       "  (17, 20),\n",
       "  (21, 27),\n",
       "  (28, 31),\n",
       "  (32, 33),\n",
       "  (34, 42),\n",
       "  (43, 52),\n",
       "  (52, 53),\n",
       "  (54, 56),\n",
       "  (56, 58),\n",
       "  (59, 62),\n",
       "  (63, 67),\n",
       "  (68, 76),\n",
       "  (76, 77),\n",
       "  (77, 78),\n",
       "  (79, 83),\n",
       "  (84, 88),\n",
       "  (89, 91),\n",
       "  (92, 93),\n",
       "  (94, 100),\n",
       "  (101, 107),\n",
       "  (108, 110),\n",
       "  (111, 114),\n",
       "  (115, 121),\n",
       "  (122, 126),\n",
       "  (126, 127),\n",
       "  (128, 139),\n",
       "  (140, 142),\n",
       "  (143, 148),\n",
       "  (149, 151),\n",
       "  (152, 155),\n",
       "  (156, 160),\n",
       "  (161, 169),\n",
       "  (170, 173),\n",
       "  (174, 180),\n",
       "  (181, 183),\n",
       "  (183, 184),\n",
       "  (185, 187),\n",
       "  (188, 189),\n",
       "  (190, 196),\n",
       "  (197, 203),\n",
       "  (204, 206),\n",
       "  (207, 213),\n",
       "  (214, 218),\n",
       "  (219, 223),\n",
       "  (224, 226),\n",
       "  (226, 229),\n",
       "  (229, 232),\n",
       "  (233, 237),\n",
       "  (238, 241),\n",
       "  (242, 248),\n",
       "  (249, 250),\n",
       "  (250, 251),\n",
       "  (251, 254),\n",
       "  (254, 256),\n",
       "  (257, 259),\n",
       "  (260, 262),\n",
       "  (263, 264),\n",
       "  (264, 265),\n",
       "  (265, 268),\n",
       "  (268, 269),\n",
       "  (269, 270),\n",
       "  (271, 275),\n",
       "  (276, 278),\n",
       "  (279, 282),\n",
       "  (283, 287),\n",
       "  (288, 296),\n",
       "  (297, 299),\n",
       "  (300, 303),\n",
       "  (304, 312),\n",
       "  (313, 315),\n",
       "  (316, 319),\n",
       "  (320, 326),\n",
       "  (327, 332),\n",
       "  (332, 333),\n",
       "  (334, 345),\n",
       "  (346, 352),\n",
       "  (353, 356),\n",
       "  (357, 358),\n",
       "  (358, 361),\n",
       "  (361, 365),\n",
       "  (366, 368),\n",
       "  (369, 372),\n",
       "  (373, 374),\n",
       "  (0, 0)],\n",
       " [(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (174, 180),\n",
       "  (181, 183),\n",
       "  (183, 184),\n",
       "  (185, 187),\n",
       "  (188, 189),\n",
       "  (190, 196),\n",
       "  (197, 203),\n",
       "  (204, 206),\n",
       "  (207, 213),\n",
       "  (214, 218),\n",
       "  (219, 223),\n",
       "  (224, 226),\n",
       "  (226, 229),\n",
       "  (229, 232),\n",
       "  (233, 237),\n",
       "  (238, 241),\n",
       "  (242, 248),\n",
       "  (249, 250),\n",
       "  (250, 251),\n",
       "  (251, 254),\n",
       "  (254, 256),\n",
       "  (257, 259),\n",
       "  (260, 262),\n",
       "  (263, 264),\n",
       "  (264, 265),\n",
       "  (265, 268),\n",
       "  (268, 269),\n",
       "  (269, 270),\n",
       "  (271, 275),\n",
       "  (276, 278),\n",
       "  (279, 282),\n",
       "  (283, 287),\n",
       "  (288, 296),\n",
       "  (297, 299),\n",
       "  (300, 303),\n",
       "  (304, 312),\n",
       "  (313, 315),\n",
       "  (316, 319),\n",
       "  (320, 326),\n",
       "  (327, 332),\n",
       "  (332, 333),\n",
       "  (334, 345),\n",
       "  (346, 352),\n",
       "  (353, 356),\n",
       "  (357, 358),\n",
       "  (358, 361),\n",
       "  (361, 365),\n",
       "  (366, 368),\n",
       "  (369, 372),\n",
       "  (373, 374),\n",
       "  (374, 377),\n",
       "  (377, 379),\n",
       "  (379, 380),\n",
       "  (381, 382),\n",
       "  (383, 389),\n",
       "  (390, 395),\n",
       "  (396, 398),\n",
       "  (399, 405),\n",
       "  (406, 409),\n",
       "  (410, 420),\n",
       "  (420, 421),\n",
       "  (422, 424),\n",
       "  (425, 427),\n",
       "  (428, 429),\n",
       "  (430, 437),\n",
       "  (438, 440),\n",
       "  (441, 444),\n",
       "  (445, 446),\n",
       "  (446, 449),\n",
       "  (449, 451),\n",
       "  (452, 454),\n",
       "  (455, 458),\n",
       "  (458, 462),\n",
       "  (462, 463),\n",
       "  (464, 470),\n",
       "  (471, 476),\n",
       "  (477, 480),\n",
       "  (481, 487),\n",
       "  (488, 492),\n",
       "  (493, 500),\n",
       "  (500, 502),\n",
       "  (503, 511),\n",
       "  (512, 514),\n",
       "  (515, 520),\n",
       "  (521, 525),\n",
       "  (525, 528),\n",
       "  (0, 0)],\n",
       " [(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (313, 315),\n",
       "  (316, 319),\n",
       "  (320, 326),\n",
       "  (327, 332),\n",
       "  (332, 333),\n",
       "  (334, 345),\n",
       "  (346, 352),\n",
       "  (353, 356),\n",
       "  (357, 358),\n",
       "  (358, 361),\n",
       "  (361, 365),\n",
       "  (366, 368),\n",
       "  (369, 372),\n",
       "  (373, 374),\n",
       "  (374, 377),\n",
       "  (377, 379),\n",
       "  (379, 380),\n",
       "  (381, 382),\n",
       "  (383, 389),\n",
       "  (390, 395),\n",
       "  (396, 398),\n",
       "  (399, 405),\n",
       "  (406, 409),\n",
       "  (410, 420),\n",
       "  (420, 421),\n",
       "  (422, 424),\n",
       "  (425, 427),\n",
       "  (428, 429),\n",
       "  (430, 437),\n",
       "  (438, 440),\n",
       "  (441, 444),\n",
       "  (445, 446),\n",
       "  (446, 449),\n",
       "  (449, 451),\n",
       "  (452, 454),\n",
       "  (455, 458),\n",
       "  (458, 462),\n",
       "  (462, 463),\n",
       "  (464, 470),\n",
       "  (471, 476),\n",
       "  (477, 480),\n",
       "  (481, 487),\n",
       "  (488, 492),\n",
       "  (493, 500),\n",
       "  (500, 502),\n",
       "  (503, 511),\n",
       "  (512, 514),\n",
       "  (515, 520),\n",
       "  (521, 525),\n",
       "  (525, 528),\n",
       "  (528, 531),\n",
       "  (532, 534),\n",
       "  (534, 537),\n",
       "  (537, 541),\n",
       "  (542, 544),\n",
       "  (545, 549),\n",
       "  (549, 550),\n",
       "  (551, 553),\n",
       "  (554, 557),\n",
       "  (558, 561),\n",
       "  (562, 564),\n",
       "  (565, 568),\n",
       "  (569, 573),\n",
       "  (574, 579),\n",
       "  (580, 581),\n",
       "  (581, 584),\n",
       "  (585, 587),\n",
       "  (588, 589),\n",
       "  (590, 596),\n",
       "  (597, 601),\n",
       "  (602, 606),\n",
       "  (607, 615),\n",
       "  (616, 623),\n",
       "  (624, 625),\n",
       "  (626, 633),\n",
       "  (634, 637),\n",
       "  (638, 641),\n",
       "  (642, 646),\n",
       "  (647, 651),\n",
       "  (651, 652),\n",
       "  (652, 653),\n",
       "  (654, 656),\n",
       "  (657, 658),\n",
       "  (659, 665),\n",
       "  (665, 666),\n",
       "  (667, 673),\n",
       "  (0, 0)],\n",
       " [(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (458, 462),\n",
       "  (462, 463),\n",
       "  (464, 470),\n",
       "  (471, 476),\n",
       "  (477, 480),\n",
       "  (481, 487),\n",
       "  (488, 492),\n",
       "  (493, 500),\n",
       "  (500, 502),\n",
       "  (503, 511),\n",
       "  (512, 514),\n",
       "  (515, 520),\n",
       "  (521, 525),\n",
       "  (525, 528),\n",
       "  (528, 531),\n",
       "  (532, 534),\n",
       "  (534, 537),\n",
       "  (537, 541),\n",
       "  (542, 544),\n",
       "  (545, 549),\n",
       "  (549, 550),\n",
       "  (551, 553),\n",
       "  (554, 557),\n",
       "  (558, 561),\n",
       "  (562, 564),\n",
       "  (565, 568),\n",
       "  (569, 573),\n",
       "  (574, 579),\n",
       "  (580, 581),\n",
       "  (581, 584),\n",
       "  (585, 587),\n",
       "  (588, 589),\n",
       "  (590, 596),\n",
       "  (597, 601),\n",
       "  (602, 606),\n",
       "  (607, 615),\n",
       "  (616, 623),\n",
       "  (624, 625),\n",
       "  (626, 633),\n",
       "  (634, 637),\n",
       "  (638, 641),\n",
       "  (642, 646),\n",
       "  (647, 651),\n",
       "  (651, 652),\n",
       "  (652, 653),\n",
       "  (654, 656),\n",
       "  (657, 658),\n",
       "  (659, 665),\n",
       "  (665, 666),\n",
       "  (667, 673),\n",
       "  (674, 679),\n",
       "  (680, 686),\n",
       "  (687, 689),\n",
       "  (690, 694),\n",
       "  (694, 695),\n",
       "  (0, 0)]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is this (weirdly named) offset_mapping?\n",
    "# it tells us the location of each token\n",
    "# notes:\n",
    "# special tokens take up 0 space - (0, 0)\n",
    "# the question portion is the same for each sample\n",
    "# the context portion starting point inceases in each sample\n",
    "inputs['offset_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03ae9e27-612f-48b6-a969-38057ded4292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['offset_mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "418563c4-24db-4e06-bc03-a2cb2a33bc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['offset_mapping'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b256a00-cb26-41d5-91ad-dca47ab0bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.sequence_ids(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cb49dd0f-93ff-4102-96c0-f7187290521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem: the position of the answer will change in each\n",
    "# window of the context\n",
    "# the answer is also the target for the neural network\n",
    "# how can we recompute the targets for each context window?\n",
    "\n",
    "# since we took the question and context from this sample earlier\n",
    "answer = raw_datasets[\"train\"][1][\"answers\"]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e11b6a39-65d2-4a90-82f1-ae7e159129e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs.sequence_ids(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ce3e7f7e-b616-457d-8254-fe4794adc068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 98)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the start and end of the context (the first and last '1')\n",
    "sequence_ids = inputs.sequence_ids(0)\n",
    "\n",
    "ctx_start = sequence_ids.index(1) # first occurrence\n",
    "ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1 # last occurrence\n",
    "\n",
    "ctx_start, ctx_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f721406a-8f10-4721-9434-3d904448ea6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ebc5a212-fa1c-4183-b73e-89fc7ddae0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_ids[::-1].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cdc75e46-86b1-412a-96cc-d0a3feb5a906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4c11ad8-58f2-49b4-b6e9-912ea5707a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 57)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether or not the answer is fully contained within the context\n",
    "# if not, target is (start, end) = (0, 0)\n",
    "\n",
    "ans_start_char = answer['answer_start'][0]\n",
    "ans_end_char = ans_start_char + len(answer['text'][0])\n",
    "\n",
    "offset = inputs['offset_mapping'][0]\n",
    "\n",
    "start_idx = 0\n",
    "end_idx = 0\n",
    "\n",
    "if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
    "  print(\"target is (0, 0)\")\n",
    "  # nothing else to do\n",
    "else:\n",
    "  # find the start and end TOKEN positions\n",
    "\n",
    "  # the 'trick' is knowing what is in units of tokens and what is in\n",
    "  # units of characters\n",
    "\n",
    "  # recall: the offset_mapping contains the character positions of each token\n",
    "\n",
    "  i = ctx_start\n",
    "  for start_end_char in offset[ctx_start:]:\n",
    "    start, end = start_end_char\n",
    "    if start == ans_start_char:\n",
    "      start_idx = i\n",
    "      # don't break yet\n",
    "    \n",
    "    if end == ans_end_char:\n",
    "      end_idx = i\n",
    "      break\n",
    "\n",
    "    i += 1\n",
    "\n",
    "start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b0bacf1c-d367-4cd5-acc6-cb8ab89e1339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[170, 7335, 5921, 1104, 4028]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "input_ids = inputs['input_ids'][0]\n",
    "input_ids[start_idx : end_idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5ff91b35-0aa3-41ba-8fdc-367f3c2847c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a copper statue of Christ'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[start_idx : end_idx + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4845b0b-b83e-4937-8b09-a82760ac2b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer_token_idx(\n",
    "    ctx_start,\n",
    "    ctx_end,\n",
    "    ans_start_char,\n",
    "    ans_end_char,\n",
    "    offset):\n",
    "  \n",
    "  start_idx = 0\n",
    "  end_idx = 0\n",
    "\n",
    "  if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
    "    pass\n",
    "    # print(\"target is (0, 0)\")\n",
    "    # nothing else to do\n",
    "  else:\n",
    "    # find the start and end TOKEN positions\n",
    "\n",
    "    # the 'trick' is knowing what is in units of tokens and what is in\n",
    "    # units of characters\n",
    "\n",
    "    # recall: the offset_mapping contains the character positions of each token\n",
    "\n",
    "    i = ctx_start\n",
    "    for start_end_char in offset[ctx_start:]:\n",
    "      start, end = start_end_char\n",
    "      if start == ans_start_char:\n",
    "        start_idx = i\n",
    "        # don't break yet\n",
    "      \n",
    "      if end == ans_end_char:\n",
    "        end_idx = i\n",
    "        break\n",
    "\n",
    "      i += 1\n",
    "  return start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "007ed028-8da7-4f29-8b4a-f57c9cc5c0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([53, 17, 0, 0], [57, 21, 0, 0])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it on all context windows\n",
    "# sometimes, the answer won't appear!\n",
    "\n",
    "start_idxs = []\n",
    "end_idxs = []\n",
    "\n",
    "for i, offset in enumerate(inputs['offset_mapping']):\n",
    "  # the final window may not be full size - can't assume 100\n",
    "  sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "  # find start + end of context (first 1 and last 1)\n",
    "  ctx_start = sequence_ids.index(1)\n",
    "  ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1\n",
    "\n",
    "  start_idx, end_idx = find_answer_token_idx(\n",
    "    ctx_start,\n",
    "    ctx_end,\n",
    "    ans_start_char,\n",
    "    ans_end_char,\n",
    "    offset)\n",
    "\n",
    "  start_idxs.append(start_idx)\n",
    "  end_idxs.append(end_idx)\n",
    "\n",
    "start_idxs, end_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5eb28653-8b06-48ff-8f61-0492134d8b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In what city and state did Beyonce  grow up? \n",
      " The album, Dangerously in Love  achieved what spot on the Billboard Top 100 chart?\n",
      "Which song did Beyonce sing at the first couple's inaugural ball? \n",
      "What event did Beyoncé perform at one month after Obama's inauguration? \n",
      "Where was the album released? \n",
      "What movie influenced Beyonce towards empowerment themes? \n"
     ]
    }
   ],
   "source": [
    "# some questions have leading and/or trailing whitespace\n",
    "for q in raw_datasets[\"train\"][\"question\"][:1000]:\n",
    "  if q.strip() != q:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f14aacb2-a8d9-4dd2-a96c-953331d3f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are ready to process (tokenize) the training data\n",
    "# (i.e. expand question+context pairs into question+smaller context windows)\n",
    "\n",
    "# Google used 384 for SQuAD\n",
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "def tokenize_fn_train(batch):\n",
    "  # some questions have leading and/or trailing whitespace\n",
    "  questions = [q.strip() for q in batch[\"question\"]]\n",
    "\n",
    "  # tokenize the data (with padding this time)\n",
    "  # since most contexts are long, we won't bother to pad per-minibatch\n",
    "  inputs = tokenizer(\n",
    "    questions,\n",
    "    batch[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    stride=stride,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",\n",
    "  )\n",
    "\n",
    "  # we don't need these later so remove them\n",
    "  offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "  orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "  answers = batch['answers']\n",
    "  start_idxs, end_idxs = [], []\n",
    "\n",
    "  # same loop as above\n",
    "  for i, offset in enumerate(offset_mapping):\n",
    "    sample_idx = orig_sample_idxs[i]\n",
    "    answer = answers[sample_idx]\n",
    "\n",
    "    ans_start_char = answer['answer_start'][0]\n",
    "    ans_end_char = ans_start_char + len(answer['text'][0])\n",
    "\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    # find start + end of context (first 1 and last 1)\n",
    "    ctx_start = sequence_ids.index(1)\n",
    "    ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1\n",
    "\n",
    "    start_idx, end_idx = find_answer_token_idx(\n",
    "      ctx_start,\n",
    "      ctx_end,\n",
    "      ans_start_char,\n",
    "      ans_end_char,\n",
    "      offset)\n",
    "\n",
    "    start_idxs.append(start_idx)\n",
    "    end_idxs.append(end_idx)\n",
    "  \n",
    "  inputs[\"start_positions\"] = start_idxs\n",
    "  inputs[\"end_positions\"] = end_idxs\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bcef8ff5-ed4b-4307-a57c-c0aabdd34daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87599, 88729)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "  tokenize_fn_train,\n",
    "  batched=True,\n",
    "  remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "800bc15d-a736-4dc6-8674-ac4f0daeb09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "  'answer_start': [177, 177, 177]}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: we'll keep these IDs for later\n",
    "raw_datasets[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "20950eea-3de0-457b-a4b2-072c28ecc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the validation set differently\n",
    "# we won't need the targets since we will just compare with the original answer\n",
    "# also: overwrite offset_mapping with Nones in place of question\n",
    "def tokenize_fn_validation(batch):\n",
    "  # some questions have leading and/or trailing whitespace\n",
    "  questions = [q.strip() for q in batch[\"question\"]]\n",
    "\n",
    "  # tokenize the data (with padding this time)\n",
    "  # since most contexts are long, we won't bother to pad per-minibatch\n",
    "  inputs = tokenizer(\n",
    "    questions,\n",
    "    batch[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    stride=stride,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",\n",
    "  )\n",
    "\n",
    "  # we don't need these later so remove them\n",
    "  orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "  sample_ids = []\n",
    "\n",
    "  # rewrite offset mapping by replacing question tuples with None\n",
    "  # this will be helpful later on when we compute metrics\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    sample_idx = orig_sample_idxs[i]\n",
    "    sample_ids.append(batch['id'][sample_idx])\n",
    "\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "      x if sequence_ids[j] == 1 else None for j, x in enumerate(offset)]\n",
    "    \n",
    "  inputs['sample_id'] = sample_ids\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd875f05-e37f-4e68-9456-b6483e261c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10570, 10822)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "  tokenize_fn_validation,\n",
    "  batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "09025adb-9fcc-40e5-8935-0a309e516b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c742efb3-d2b6-489b-acb5-0038ed2c5375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 66.66666666666667, 'f1': 83.33333333333333}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_answers = [\n",
    "  {'id': '1', 'prediction_text': 'Albert Einstein'},\n",
    "  {'id': '2', 'prediction_text': 'physicist'},\n",
    "  {'id': '3', 'prediction_text': 'general relativity'},\n",
    "]\n",
    "true_answers = [\n",
    "  {'id': '1', 'answers': {'text': ['Albert Einstein'], 'answer_start': [100]}},\n",
    "  {'id': '2', 'answers': {'text': ['physicist'], 'answer_start': [100]}},\n",
    "  {'id': '3', 'answers': {'text': ['special relativity'], 'answer_start': [100]}},\n",
    "]\n",
    "\n",
    "# id and answer_start seem superfluous but you'll get an error if not included\n",
    "# exercise: remove them (one at a time) and see!\n",
    "metric.compute(predictions=predicted_answers, references=true_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e6f7818a-bf5d-475e-906d-9bfe36208d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sthor\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-4839eb019eefdba6.arrow\n"
     ]
    }
   ],
   "source": [
    "# next problem: how to go from logits to prediction text?\n",
    "# to make it easier, let's work on an already-trained question-answering model\n",
    "small_validation_dataset = raw_datasets[\"validation\"].select(range(100))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "# temporarily assign tokenizer2 to tokenizer since it's used as a global\n",
    "# in tokenize_fn_validation\n",
    "old_tokenizer = tokenizer\n",
    "tokenizer = tokenizer2\n",
    "\n",
    "small_validation_processed = small_validation_dataset.map(\n",
    "    tokenize_fn_validation,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "\n",
    "# change it back\n",
    "tokenizer = old_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9a53c8a6-341e-4464-a4eb-04c7a1d90771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model outputs\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "# the trained model doesn't use these columns\n",
    "small_model_inputs = small_validation_processed.remove_columns(\n",
    "  [\"sample_id\", \"offset_mapping\"])\n",
    "small_model_inputs.set_format(\"torch\")\n",
    "\n",
    "# get gpu device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# move tensors to gpu device\n",
    "small_model_inputs_gpu = {\n",
    "  k: small_model_inputs[k].to(device) for k in small_model_inputs.column_names\n",
    "}\n",
    "\n",
    "# download the model\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "  trained_checkpoint).to(device)\n",
    "\n",
    "# get the model outputs\n",
    "with torch.no_grad():\n",
    "  outputs = trained_model(**small_model_inputs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dec260ca-2263-4682-8464-1f9d4cc56e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ -2.2607,  -5.1783,  -5.2709,  ...,  -9.5243,  -9.5183,  -9.5288],\n",
       "        [ -2.5961,  -5.5482,  -5.5313,  ...,  -9.9598,  -9.9533,  -9.9860],\n",
       "        [ -3.7127,  -7.1848,  -8.5388,  ..., -11.6557, -11.6571, -11.6505],\n",
       "        ...,\n",
       "        [ -2.0260,  -4.4167,  -4.4980,  ...,  -8.1479,  -8.1530,  -8.1760],\n",
       "        [ -4.1553,  -5.8304,  -7.1643,  ..., -10.5255, -10.5251, -10.4890],\n",
       "        [ -3.2000,  -5.8162,  -6.7249,  ...,  -9.4935,  -9.5038,  -9.4871]],\n",
       "       device='cuda:0'), end_logits=tensor([[ -0.7353,  -4.9235,  -5.1048,  ...,  -8.8734,  -8.8915,  -8.8550],\n",
       "        [ -1.3056,  -5.3870,  -5.4945,  ...,  -9.4895,  -9.5039,  -9.4959],\n",
       "        [ -2.7649,  -7.2201,  -9.0916,  ..., -11.3106, -11.3414, -11.2702],\n",
       "        ...,\n",
       "        [ -0.0768,  -4.8210,  -4.4374,  ...,  -8.0483,  -8.0502,  -7.9903],\n",
       "        [ -2.7347,  -5.3650,  -7.2549,  ..., -10.0498, -10.0661,  -9.9886],\n",
       "        [ -1.0991,  -4.2569,  -6.1267,  ...,  -8.6882,  -8.6889,  -8.6272]],\n",
       "       device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "46e83b5b-197e-4b3c-a282-95779de1a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fdaf64fa-883b-4294-aa93-bd11c3988844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['56be4db0acb8001400a502ec',\n",
       " '56be4db0acb8001400a502ed',\n",
       " '56be4db0acb8001400a502ee',\n",
       " '56be4db0acb8001400a502ef',\n",
       " '56be4db0acb8001400a502f0']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_validation_processed['sample_id'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f76c0d7e-9efe-4b7e-ab39-d1e00cfa2c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10822"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_dataset['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e8b55cec-fcfa-4a9c-a570-43a889209eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(validation_dataset['sample_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d448d8b-24b9-4842-85b7-a509df7a80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: {'56be4db0acb8001400a502ec': [0, 1, 2, 3], ...}\n",
    "sample_id2idxs = {}\n",
    "for i, id_ in enumerate(small_validation_processed['sample_id']):\n",
    "  if id_ not in sample_id2idxs:\n",
    "    sample_id2idxs[id_] = [i]\n",
    "  else:\n",
    "    print(\"here\")\n",
    "    sample_id2idxs[id_].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf5390ea-2910-4180-ac9d-b322ec7bfa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 384), (100, 384))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits.shape, end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9369ef7f-4aaa-4e87-80fb-2c79641dc9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46,  57,  47,  38,  39,  58,  50,  43,  45,  54,  56,  49,  13,\n",
       "        42,  40,  35,  27,  31,  48,  41,  53,  44,  37,  59,  78,  15,\n",
       "         0,  52,  24,  65,  81,  70,  18,  51,  55,  26,  69,  29,  28,\n",
       "        75,  61,  64,  23,  36,  32,  11, 101,  62,  66,  34,  95,  30,\n",
       "        63,  21,  19,  20,  17,  14,  22,  33,  68,  87, 171,  12,  76,\n",
       "        71,  73,  92, 110,  84, 151,   1,  74,   2,   6,  16,  80,  79,\n",
       "       105,  98,  10,  96, 136, 169, 106, 100,  93, 165,  67, 109,   8,\n",
       "        90,   3, 115,  60,   5,  97,   7, 103, 102,  86,  72, 111,  89,\n",
       "       108,   4,  88,  25, 132,  77, 123, 150, 124, 153,  83, 118,  82,\n",
       "        85, 107, 114, 143, 164, 137, 130, 166, 159, 131,  91,   9, 144,\n",
       "       139, 160,  94, 141, 128, 112, 134, 152, 170, 154, 117, 127, 104,\n",
       "       140, 157, 155, 133, 145, 119, 162, 138, 135, 156, 167, 168, 126,\n",
       "       148, 163, 161, 116,  99, 120, 142, 158, 125, 146, 113, 121, 147,\n",
       "       149, 129, 122, 311, 312, 304, 309, 313, 310, 300, 307, 316, 308,\n",
       "       314, 306, 317, 320, 319, 321, 291, 318, 301, 305, 287, 270, 315,\n",
       "       295, 289, 294, 251, 333, 303, 269, 299, 274, 265, 298, 176, 175,\n",
       "       338, 292, 323, 322, 290, 252, 296, 229, 177, 302, 297, 186, 245,\n",
       "       250, 283, 174, 256, 337, 266, 190, 293, 286, 264, 288, 331, 327,\n",
       "       234, 237, 227, 284, 255, 326, 276, 272, 233, 346, 191, 230, 218,\n",
       "       232, 179, 285, 273, 173, 187, 239, 332, 172, 267, 329, 238, 253,\n",
       "       334, 214, 192, 325, 278, 350, 259, 281, 268, 185, 254, 271, 279,\n",
       "       342, 345, 343, 181, 335, 183, 189, 260, 341, 275, 178, 228, 210,\n",
       "       324, 277, 212, 348, 209, 336, 261, 240, 249, 246, 194, 257, 182,\n",
       "       377, 258, 196, 195, 248, 188, 339, 197, 213, 378, 263, 208, 201,\n",
       "       205, 200, 225, 211, 282, 236, 204, 347, 203, 262, 223, 193, 330,\n",
       "       199, 202, 349, 184, 180, 351, 340, 226, 224, 243, 217, 372, 244,\n",
       "       241, 207, 235, 344, 215, 367, 247, 368, 382, 352, 379, 353, 221,\n",
       "       376, 231, 380, 220, 371, 366, 242, 219, 381, 206, 375, 369, 216,\n",
       "       198, 355, 383, 280, 328, 222, 358, 373, 357, 363, 356, 374, 354,\n",
       "       359, 365, 370, 364, 362, 361, 360], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reminder of how to find indices with the largest values\n",
    "(-start_logits[0]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d9cdbe46-1a58-4eba-ba7b-3a857d4f56f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.6944475 ,  9.803692  ,  4.459978  ,  4.400489  ,  2.943783  ,\n",
       "        2.701741  ,  2.0126514 ,  1.5780798 ,  0.52237433,  0.02074171,\n",
       "       -0.02802034, -0.04970592, -0.38572612, -0.69453436, -0.79794055,\n",
       "       -0.86779696, -0.87220407, -1.3516837 , -1.3703655 , -1.3878771 ,\n",
       "       -1.5135038 , -1.7355443 , -1.8827006 , -1.8932816 , -1.9078884 ,\n",
       "       -1.9304936 , -2.2607267 , -2.2983844 , -2.306928  , -2.502734  ,\n",
       "       -2.5100558 , -2.5308352 , -2.5399885 , -2.671805  , -2.7323487 ,\n",
       "       -2.7710135 , -2.771363  , -2.9521275 , -3.0604608 , -3.170598  ,\n",
       "       -3.2045414 , -3.5693343 , -3.5797982 , -3.6668768 , -3.7250552 ,\n",
       "       -3.749851  , -3.7632062 , -3.9968095 , -4.0113215 , -4.0687923 ,\n",
       "       -4.0944796 , -4.1954694 , -4.238307  , -4.3323574 , -4.3524084 ,\n",
       "       -4.3879557 , -4.3886027 , -4.3966055 , -4.6790457 , -4.7030253 ,\n",
       "       -4.775753  , -4.7778063 , -4.78821   , -4.7882366 , -4.822121  ,\n",
       "       -4.8725357 , -4.8849297 , -4.898141  , -5.0720897 , -5.1078672 ,\n",
       "       -5.1486316 , -5.1783166 , -5.191201  , -5.270892  , -5.3146334 ,\n",
       "       -5.377068  , -5.5316434 , -5.5711203 , -5.64981   , -5.661299  ,\n",
       "       -5.6778693 , -5.6986046 , -5.7515616 , -5.8426366 , -5.862144  ,\n",
       "       -5.9076824 , -5.9093695 , -5.944442  , -5.996887  , -6.0058208 ,\n",
       "       -6.047026  , -6.064002  , -6.0858717 , -6.1005507 , -6.224171  ,\n",
       "       -6.267086  , -6.2752824 , -6.3032885 , -6.3134103 , -6.3287935 ,\n",
       "       -6.3306823 , -6.401478  , -6.4204764 , -6.436103  , -6.437401  ,\n",
       "       -6.4507065 , -6.5314245 , -6.553036  , -6.563014  , -6.668787  ,\n",
       "       -6.726683  , -6.742624  , -6.7442884 , -6.74585   , -6.8108683 ,\n",
       "       -6.9216223 , -6.949294  , -6.990759  , -6.9987383 , -7.1622524 ,\n",
       "       -7.167349  , -7.1756506 , -7.1805525 , -7.1967783 , -7.243588  ,\n",
       "       -7.2733364 , -7.2769403 , -7.300215  , -7.300926  , -7.3218517 ,\n",
       "       -7.3976707 , -7.4330263 , -7.5248423 , -7.5272236 , -7.532266  ,\n",
       "       -7.573702  , -7.598206  , -7.6580915 , -7.6597023 , -7.7155676 ,\n",
       "       -7.718398  , -7.7400103 , -7.754643  , -7.8856373 , -7.893758  ,\n",
       "       -7.8943634 , -7.9380274 , -7.958199  , -8.037509  , -8.059212  ,\n",
       "       -8.063905  , -8.104623  , -8.117325  , -8.138479  , -8.145771  ,\n",
       "       -8.221213  , -8.274242  , -8.292216  , -8.293198  , -8.316824  ,\n",
       "       -8.317487  , -8.333991  , -8.466503  , -8.500572  , -8.502026  ,\n",
       "       -8.591025  , -8.612459  , -8.621487  , -8.625206  , -8.62545   ,\n",
       "       -8.814253  , -9.03905   , -9.421049  , -9.434788  , -9.441462  ,\n",
       "       -9.444368  , -9.4498415 , -9.450166  , -9.450432  , -9.45104   ,\n",
       "       -9.452057  , -9.452418  , -9.452507  , -9.454125  , -9.456524  ,\n",
       "       -9.458099  , -9.458333  , -9.458435  , -9.458744  , -9.460869  ,\n",
       "       -9.46207   , -9.462503  , -9.462942  , -9.463785  , -9.463888  ,\n",
       "       -9.465518  , -9.466445  , -9.468557  , -9.468851  , -9.468952  ,\n",
       "       -9.469486  , -9.469515  , -9.470055  , -9.470963  , -9.47113   ,\n",
       "       -9.471281  , -9.4713545 , -9.471783  , -9.471888  , -9.47204   ,\n",
       "       -9.472681  , -9.472955  , -9.473706  , -9.475194  , -9.476604  ,\n",
       "       -9.476759  , -9.476778  , -9.477406  , -9.478308  , -9.478865  ,\n",
       "       -9.479742  , -9.479913  , -9.4800625 , -9.480641  , -9.481184  ,\n",
       "       -9.481464  , -9.481514  , -9.48152   , -9.481606  , -9.481785  ,\n",
       "       -9.482158  , -9.482844  , -9.483407  , -9.484568  , -9.484699  ,\n",
       "       -9.48489   , -9.4851675 , -9.485298  , -9.485711  , -9.485956  ,\n",
       "       -9.486797  , -9.486966  , -9.487625  , -9.487724  , -9.487907  ,\n",
       "       -9.487988  , -9.48829   , -9.488392  , -9.4885845 , -9.488797  ,\n",
       "       -9.488953  , -9.489096  , -9.489483  , -9.489668  , -9.489997  ,\n",
       "       -9.490799  , -9.490829  , -9.490864  , -9.490892  , -9.491135  ,\n",
       "       -9.491253  , -9.491706  , -9.492022  , -9.492159  , -9.492529  ,\n",
       "       -9.492813  , -9.493553  , -9.493629  , -9.493648  , -9.493998  ,\n",
       "       -9.494022  , -9.494385  , -9.495197  , -9.49542   , -9.496527  ,\n",
       "       -9.496593  , -9.497129  , -9.497522  , -9.497557  , -9.497571  ,\n",
       "       -9.497601  , -9.497608  , -9.498009  , -9.498117  , -9.498621  ,\n",
       "       -9.49864   , -9.498763  , -9.499582  , -9.5000105 , -9.5003395 ,\n",
       "       -9.500416  , -9.500575  , -9.500973  , -9.500994  , -9.5011635 ,\n",
       "       -9.501213  , -9.501273  , -9.501429  , -9.501503  , -9.501879  ,\n",
       "       -9.502005  , -9.502516  , -9.502678  , -9.503555  , -9.5036335 ,\n",
       "       -9.503653  , -9.504163  , -9.504543  , -9.505044  , -9.505528  ,\n",
       "       -9.506168  , -9.506632  , -9.506673  , -9.50675   , -9.506827  ,\n",
       "       -9.507115  , -9.507551  , -9.507721  , -9.507982  , -9.508043  ,\n",
       "       -9.508078  , -9.508727  , -9.508767  , -9.508854  , -9.509268  ,\n",
       "       -9.509505  , -9.509523  , -9.510817  , -9.511486  , -9.512024  ,\n",
       "       -9.512419  , -9.512816  , -9.513131  , -9.513147  , -9.513184  ,\n",
       "       -9.513232  , -9.513382  , -9.514925  , -9.515434  , -9.515566  ,\n",
       "       -9.51618   , -9.516237  , -9.516339  , -9.516373  , -9.516654  ,\n",
       "       -9.517011  , -9.518308  , -9.51846   , -9.518789  , -9.519087  ,\n",
       "       -9.520796  , -9.520998  , -9.521181  , -9.521225  , -9.522533  ,\n",
       "       -9.522736  , -9.522879  , -9.523228  , -9.523891  , -9.5243225 ,\n",
       "       -9.525371  , -9.526033  , -9.527025  , -9.528465  , -9.5285225 ,\n",
       "       -9.528618  , -9.528755  , -9.529452  , -9.529709  , -9.531363  ,\n",
       "       -9.53236   , -9.53274   , -9.535533  , -9.536642  , -9.537704  ,\n",
       "       -9.538656  , -9.539046  , -9.539334  , -9.540261  , -9.541702  ,\n",
       "       -9.548324  , -9.554476  , -9.557679  , -9.567395  ], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits[0][(-start_logits[0]).argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "118bbd6a-ab7a-46b2-aeb7-bc263ad5974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " [0, 5],\n",
       " [6, 10],\n",
       " [11, 13],\n",
       " [14, 17],\n",
       " [18, 20],\n",
       " [21, 29],\n",
       " [30, 38],\n",
       " [39, 43],\n",
       " [44, 46],\n",
       " [47, 56],\n",
       " [57, 60],\n",
       " [61, 69],\n",
       " [70, 72],\n",
       " [73, 76],\n",
       " [77, 85],\n",
       " [86, 94],\n",
       " [95, 101],\n",
       " [102, 103],\n",
       " [103, 106],\n",
       " [106, 107],\n",
       " [108, 111],\n",
       " [112, 115],\n",
       " [116, 120],\n",
       " [121, 127],\n",
       " [127, 128],\n",
       " [129, 132],\n",
       " [133, 141],\n",
       " [142, 150],\n",
       " [151, 161],\n",
       " [162, 163],\n",
       " [163, 166],\n",
       " [166, 167],\n",
       " [168, 176],\n",
       " [177, 183],\n",
       " [184, 191],\n",
       " [192, 200],\n",
       " [201, 204],\n",
       " [205, 213],\n",
       " [214, 222],\n",
       " [223, 233],\n",
       " [234, 235],\n",
       " [235, 238],\n",
       " [238, 239],\n",
       " [240, 248],\n",
       " [249, 257],\n",
       " [258, 266],\n",
       " [267, 269],\n",
       " [269, 270],\n",
       " [270, 272],\n",
       " [273, 275],\n",
       " [276, 280],\n",
       " [281, 286],\n",
       " [287, 292],\n",
       " [293, 298],\n",
       " [299, 303],\n",
       " [304, 309],\n",
       " [309, 310],\n",
       " [311, 314],\n",
       " [315, 319],\n",
       " [320, 323],\n",
       " [324, 330],\n",
       " [331, 333],\n",
       " [334, 342],\n",
       " [343, 344],\n",
       " [344, 345],\n",
       " [346, 350],\n",
       " [350, 351],\n",
       " [352, 354],\n",
       " [355, 359],\n",
       " [359, 360],\n",
       " [360, 361],\n",
       " [362, 369],\n",
       " [370, 372],\n",
       " [373, 376],\n",
       " [377, 380],\n",
       " [381, 390],\n",
       " [391, 394],\n",
       " [395, 399],\n",
       " [400, 402],\n",
       " [403, 408],\n",
       " [409, 414],\n",
       " [414, 415],\n",
       " [416, 426],\n",
       " [426, 427],\n",
       " [428, 430],\n",
       " [431, 435],\n",
       " [436, 439],\n",
       " [440, 443],\n",
       " [444, 448],\n",
       " [449, 454],\n",
       " [455, 459],\n",
       " [459, 460],\n",
       " [461, 464],\n",
       " [465, 471],\n",
       " [472, 482],\n",
       " [483, 486],\n",
       " [487, 488],\n",
       " [488, 494],\n",
       " [495, 506],\n",
       " [506, 507],\n",
       " [508, 512],\n",
       " [513, 520],\n",
       " [521, 525],\n",
       " [525, 526],\n",
       " [526, 532],\n",
       " [533, 544],\n",
       " [544, 545],\n",
       " [546, 548],\n",
       " [549, 553],\n",
       " [554, 556],\n",
       " [557, 568],\n",
       " [569, 571],\n",
       " [571, 573],\n",
       " [573, 579],\n",
       " [580, 583],\n",
       " [584, 593],\n",
       " [594, 596],\n",
       " [597, 603],\n",
       " [604, 608],\n",
       " [609, 614],\n",
       " [615, 619],\n",
       " [620, 624],\n",
       " [625, 629],\n",
       " [630, 635],\n",
       " [636, 637],\n",
       " [637, 640],\n",
       " [640, 644],\n",
       " [645, 646],\n",
       " [646, 651],\n",
       " [652, 657],\n",
       " [658, 661],\n",
       " [662, 666],\n",
       " [667, 672],\n",
       " [673, 677],\n",
       " [678, 682],\n",
       " [683, 688],\n",
       " [689, 691],\n",
       " [692, 693],\n",
       " [693, 698],\n",
       " [699, 703],\n",
       " [704, 705],\n",
       " [705, 706],\n",
       " [706, 707],\n",
       " [707, 708],\n",
       " [709, 711],\n",
       " [712, 716],\n",
       " [717, 720],\n",
       " [721, 725],\n",
       " [726, 731],\n",
       " [732, 743],\n",
       " [744, 751],\n",
       " [752, 755],\n",
       " [756, 762],\n",
       " [763, 764],\n",
       " [764, 767],\n",
       " [767, 771],\n",
       " [772, 774],\n",
       " [774, 775],\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reminder: in offset_mapping we store None everywhere except the context window\n",
    "# in the context window we store tuples for each token containing:\n",
    "# (start_character_position, end_character_position)\n",
    "small_validation_processed['offset_mapping'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "606f59c1-954e-45b1-880b-3b7041ea8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_largest = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "# we are looping through the original (untokenized) dataset\n",
    "# because we need to grab the answer from the original string context\n",
    "for sample in small_validation_dataset:\n",
    "  sample_id = sample['id']\n",
    "  context = sample['context']\n",
    "\n",
    "  # update these as we loop through candidate answers\n",
    "  best_score = float('-inf')\n",
    "  best_answer = None\n",
    "\n",
    "  # now loop through the *expanded* input samples (fixed size context windows)\n",
    "  # from here we will pick the highest probability start/end combination\n",
    "  for idx in sample_id2idxs[sample_id]:\n",
    "    start_logit = start_logits[idx] # (384,) vector\n",
    "    end_logit = end_logits[idx] # (384,) vector\n",
    "    offsets = small_validation_processed[idx]['offset_mapping']\n",
    "\n",
    "    start_indices = (-start_logit).argsort()\n",
    "    end_indices = (-end_logit).argsort()\n",
    "\n",
    "    for start_idx in start_indices[:n_largest]:\n",
    "      for end_idx in end_indices[:n_largest]:\n",
    "\n",
    "        # skip answers not contained in context window\n",
    "        # recall: we set entries not pertaining to context to None earlier\n",
    "        if offsets[start_idx] is None or offsets[end_idx] is None:\n",
    "          continue\n",
    "        \n",
    "        # skip answers where end < start\n",
    "        if end_idx < start_idx:\n",
    "          continue\n",
    "        \n",
    "        # skip answers that are too long\n",
    "        if end_idx - start_idx + 1 > max_answer_length:\n",
    "          continue\n",
    "        \n",
    "        # see theory lecture for score calculation\n",
    "        score = start_logit[start_idx] + end_logit[end_idx]\n",
    "        if score > best_score:\n",
    "          best_score = score\n",
    "\n",
    "          # find positions of start and end characters\n",
    "          # recall: offsets contains tuples for each token:\n",
    "          # (start_char, end_char)\n",
    "          first_ch = offsets[start_idx][0]\n",
    "          last_ch = offsets[end_idx][1]\n",
    "\n",
    "          best_answer = context[first_ch:last_ch]\n",
    "\n",
    "  # save best answer\n",
    "  predicted_answers.append({'id': sample_id, 'prediction_text': best_answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d90dd397-df9e-480e-9de9-617351172baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       " 'answer_start': [177, 177, 177]}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_validation_dataset['answers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "71c1eb76-fabf-4c27-9b61-bd2f70c6e1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now test it!\n",
    "\n",
    "true_answers = [\n",
    "  {'id': x['id'], 'answers': x['answers']} for x in small_validation_dataset\n",
    "]\n",
    "metric.compute(predictions=predicted_answers, references=true_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0f06f684-c7a4-4b81-bcb4-46c61b1258fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's define a full compute_metrics function\n",
    "# note: this will NOT be called from the trainer\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, processed_dataset, orig_dataset):\n",
    "  # map sample_id ('56be4db0acb8001400a502ec') to row indices of processed data\n",
    "  sample_id2idxs = {}\n",
    "  for i, id_ in enumerate(processed_dataset['sample_id']):\n",
    "    if id_ not in sample_id2idxs:\n",
    "      sample_id2idxs[id_] = [i]\n",
    "    else:\n",
    "      sample_id2idxs[id_].append(i)\n",
    "\n",
    "  predicted_answers = []\n",
    "  for sample in tqdm(orig_dataset):\n",
    "\n",
    "    sample_id = sample['id']\n",
    "    context = sample['context']\n",
    "\n",
    "    # update these as we loop through candidate answers\n",
    "    best_score = float('-inf')\n",
    "    best_answer = None\n",
    "\n",
    "    # now loop through the *expanded* input samples (fixed size context windows)\n",
    "    # from here we will pick the highest probability start/end combination\n",
    "    for idx in sample_id2idxs[sample_id]:\n",
    "      start_logit = start_logits[idx] # (T,) vector\n",
    "      end_logit = end_logits[idx] # (T,) vector\n",
    "\n",
    "      # note: do NOT do the reverse: ['offset_mapping'][idx]\n",
    "      offsets = processed_dataset[idx]['offset_mapping']\n",
    "\n",
    "      start_indices = (-start_logit).argsort()\n",
    "      end_indices = (-end_logit).argsort()\n",
    "\n",
    "      for start_idx in start_indices[:n_largest]:\n",
    "        for end_idx in end_indices[:n_largest]:\n",
    "\n",
    "          # skip answers not contained in context window\n",
    "          # recall: we set entries not pertaining to context to None earlier\n",
    "          if offsets[start_idx] is None or offsets[end_idx] is None:\n",
    "            continue\n",
    "          \n",
    "          # skip answers where end < start\n",
    "          if end_idx < start_idx:\n",
    "            continue\n",
    "          \n",
    "          # skip answers that are too long\n",
    "          if end_idx - start_idx + 1 > max_answer_length:\n",
    "            continue\n",
    "          \n",
    "          # see theory lecture for score calculation\n",
    "          score = start_logit[start_idx] + end_logit[end_idx]\n",
    "          if score > best_score:\n",
    "            best_score = score\n",
    "\n",
    "            # find positions of start and end characters\n",
    "            # recall: offsets contains tuples for each token:\n",
    "            # (start_char, end_char)\n",
    "            first_ch = offsets[start_idx][0]\n",
    "            last_ch = offsets[end_idx][1]\n",
    "\n",
    "            best_answer = context[first_ch:last_ch]\n",
    "\n",
    "    # save best answer\n",
    "    predicted_answers.append({'id': sample_id, 'prediction_text': best_answer})\n",
    "  \n",
    "  # compute the metrics\n",
    "  true_answers = [\n",
    "    {'id': x['id'], 'answers': x['answers']} for x in orig_dataset\n",
    "  ]\n",
    "  return metric.compute(predictions=predicted_answers, references=true_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c2dbf305-672f-481e-b5d4-807276eac283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 909.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run our function on the same mini dataset as before\n",
    "compute_metrics(\n",
    "    start_logits,\n",
    "    end_logits,\n",
    "    small_validation_processed,\n",
    "    small_validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9a536-dac1-4fc6-b1b5-5759295653f4",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eee2138d-d396-4183-be02-54df10b83ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 436M/436M [00:53<00:00, 8.21MB/s] \n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# now load the model we want to fine-tune\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2614c9a8-88f8-4693-8c76-07fceaeb70e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"finetuned-squad\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d23a4a82-4159-4668-bf22-a5025edee575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33276' max='33276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33276/33276 1:37:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.372500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.263500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.212700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.141800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.069900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.811900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.729900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.768700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.777600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.740300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.740100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.722400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.743200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.748900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.728900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.723600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.737100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.511400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.536300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.514400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.518600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.497900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.535300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.497600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.495200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.497100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.484300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.477600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.489800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=33276, training_loss=0.8339634709725631, metrics={'train_runtime': 5873.4646, 'train_samples_per_second': 45.32, 'train_steps_per_second': 5.665, 'total_flos': 5.216534983896422e+16, 'train_loss': 0.8339634709725631, 'epoch': 3.0})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# takes ~2.5h with bert on full dataset\n",
    "# ~1h 15min with distilbert\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    # train_dataset=train_dataset.shuffle(seed=42).select(range(1_000)),\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a2163420-751c-4e0e-8134-bc2379155e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_output = trainer.predict(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a6d40976-445a-4860-9d7f-36901fc9b614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.trainer_utils.PredictionOutput"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "71dcada4-0c28-4c94-99a5-a80668c4fbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[ -0.966,  -9.06 , -10.15 , ..., -10.766, -10.77 , -10.76 ],\n",
       "       [ -1.801,  -9.48 , -10.26 , ..., -10.8  , -10.805, -10.79 ],\n",
       "       [ -4.75 ,  -9.48 , -10.81 , ..., -10.9  , -10.9  , -10.89 ],\n",
       "       ...,\n",
       "       [ -6.605, -10.195, -10.32 , ..., -10.7  , -10.766, -10.77 ],\n",
       "       [ -7.188, -10.42 , -10.41 , ..., -10.734, -10.78 , -10.75 ],\n",
       "       [ -7.617, -10.47 , -10.65 , ..., -10.805, -10.836, -10.836]],\n",
       "      dtype=float16), array([[ -0.3574,  -9.49  ,  -9.98  , ..., -10.62  , -10.6   , -10.625 ],\n",
       "       [ -1.261 ,  -9.99  , -10.03  , ..., -10.58  , -10.57  , -10.586 ],\n",
       "       [ -3.611 ,  -9.82  , -10.03  , ..., -10.53  , -10.53  , -10.55  ],\n",
       "       ...,\n",
       "       [ -5.477 , -10.58  , -10.766 , ..., -10.74  , -10.68  , -10.69  ],\n",
       "       [ -5.81  , -10.305 , -10.586 , ..., -10.69  , -10.66  , -10.7   ],\n",
       "       [ -6.16  , -10.19  , -10.45  , ..., -10.63  , -10.586 , -10.6   ]],\n",
       "      dtype=float16)), label_ids=None, metrics={'test_runtime': 63.0436, 'test_samples_per_second': 171.659, 'test_steps_per_second': 21.461})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "277671ca-b701-4ec8-921d-841c1e4e2b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, _, _ = trainer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0f05a1c7-e25d-460b-bd68-bbca0325cc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ -0.966,  -9.06 , -10.15 , ..., -10.766, -10.77 , -10.76 ],\n",
       "        [ -1.801,  -9.48 , -10.26 , ..., -10.8  , -10.805, -10.79 ],\n",
       "        [ -4.75 ,  -9.48 , -10.81 , ..., -10.9  , -10.9  , -10.89 ],\n",
       "        ...,\n",
       "        [ -6.605, -10.195, -10.32 , ..., -10.7  , -10.766, -10.77 ],\n",
       "        [ -7.188, -10.42 , -10.41 , ..., -10.734, -10.78 , -10.75 ],\n",
       "        [ -7.617, -10.47 , -10.65 , ..., -10.805, -10.836, -10.836]],\n",
       "       dtype=float16),\n",
       " array([[ -0.3574,  -9.49  ,  -9.98  , ..., -10.62  , -10.6   , -10.625 ],\n",
       "        [ -1.261 ,  -9.99  , -10.03  , ..., -10.58  , -10.57  , -10.586 ],\n",
       "        [ -3.611 ,  -9.82  , -10.03  , ..., -10.53  , -10.53  , -10.55  ],\n",
       "        ...,\n",
       "        [ -5.477 , -10.58  , -10.766 , ..., -10.74  , -10.68  , -10.69  ],\n",
       "        [ -5.81  , -10.305 , -10.586 , ..., -10.69  , -10.66  , -10.7   ],\n",
       "        [ -6.16  , -10.19  , -10.45  , ..., -10.63  , -10.586 , -10.6   ]],\n",
       "       dtype=float16))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "52e414ca-ce05-43e4-a280-afd14d2f5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits, end_logits = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bc1a813b-ee11-4b86-ad99-be87de617293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:11<00:00, 927.41it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 81.01229895931883, 'f1': 88.5676108449621}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\n",
    "    start_logits,\n",
    "    end_logits,\n",
    "    validation_dataset, # processed\n",
    "    raw_datasets[\"validation\"], # orig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c27089b2-b253-4bd4-a53b-719ec38661f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "184ef4c1-32bd-4b16-9d50-8fc1fbc15732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(\n",
    "  \"question-answering\",\n",
    "  model='my_saved_model',\n",
    "  device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9fe60f05-ad06-44c2-8e54-962b4d20b0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.8745125532150269,\n",
       " 'start': 38,\n",
       " 'end': 54,\n",
       " 'answer': 'a carton of milk'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Today I went to the store to purchase a carton of milk.\"\n",
    "question = \"What did I buy?\"\n",
    "\n",
    "qa(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "980daf17-1f90-48a3-ae89-59930ca86324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise: try it with bert instead of distilbert for an even higher score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191f6f3-3d4d-469d-8326-c3b8b3d599d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
