{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d7841a-d428-44a2-a9cd-8ddaddedba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a6a78c-6376-46da-84a5-94fb8e362f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, d_k, d_model, n_heads, max_len, causal=False):\n",
    "    super().__init__()\n",
    "\n",
    "    # Assume d_v = d_k\n",
    "    self.d_k = d_k\n",
    "    self.n_heads = n_heads\n",
    "\n",
    "    self.key = nn.Linear(d_model, d_k * n_heads)\n",
    "    self.query = nn.Linear(d_model, d_k * n_heads)\n",
    "    self.value = nn.Linear(d_model, d_k * n_heads)\n",
    "\n",
    "    # final linear layer\n",
    "    self.fc = nn.Linear(d_k * n_heads, d_model)\n",
    "\n",
    "    # causal mask\n",
    "    # make it so that diagonal is 0 too\n",
    "    # this way we don't have to shift the inputs to make targets\n",
    "    self.causal = causal\n",
    "    if causal:\n",
    "      cm = torch.tril(torch.ones(max_len, max_len))\n",
    "      self.register_buffer(\n",
    "          \"causal_mask\",\n",
    "          cm.view(1, 1, max_len, max_len)\n",
    "      )\n",
    "\n",
    "  def forward(self, q, k, v, pad_mask=None):\n",
    "    q = self.query(q) # N x T x (hd_k)\n",
    "    k = self.key(k)   # N x T x (hd_k)\n",
    "    v = self.value(v) # N x T x (hd_v)\n",
    "\n",
    "    N = q.shape[0]\n",
    "    T_output = q.shape[1]\n",
    "    T_input = k.shape[1]\n",
    "\n",
    "    # change the shape to:\n",
    "    # (N, T, h, d_k) -> (N, h, T, d_k)\n",
    "    # in order for matrix multiply to work properly\n",
    "    q = q.view(N, T_output, self.n_heads, self.d_k).transpose(1, 2)\n",
    "    k = k.view(N, T_input, self.n_heads, self.d_k).transpose(1, 2)\n",
    "    v = v.view(N, T_input, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    # compute attention weights\n",
    "    # (N, h, T, d_k) x (N, h, d_k, T) --> (N, h, T, T)\n",
    "    attn_scores = q @ k.transpose(-2, -1) / math.sqrt(self.d_k)\n",
    "    if pad_mask is not None:\n",
    "      attn_scores = attn_scores.masked_fill(\n",
    "          pad_mask[:, None, None, :] == 0, float('-inf'))\n",
    "    if self.causal:\n",
    "      attn_scores = attn_scores.masked_fill(\n",
    "          self.causal_mask[:, :, :T_output, :T_input] == 0, float('-inf'))\n",
    "    attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "    \n",
    "    # compute attention-weighted values\n",
    "    # (N, h, T, T) x (N, h, T, d_k) --> (N, h, T, d_k)\n",
    "    A = attn_weights @ v\n",
    "\n",
    "    # reshape it back before final linear layer\n",
    "    A = A.transpose(1, 2) # (N, T, h, d_k)\n",
    "    A = A.contiguous().view(N, T_output, self.d_k * self.n_heads) # (N, T, h*d_k)\n",
    "\n",
    "    # projection\n",
    "    return self.fc(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02141890-1a58-4974-b51a-c7ca7263339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "  def __init__(self, d_k, d_model, n_heads, max_len, dropout_prob=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.ln1 = nn.LayerNorm(d_model)\n",
    "    self.ln2 = nn.LayerNorm(d_model)\n",
    "    self.mha = MultiHeadAttention(d_k, d_model, n_heads, max_len, causal=False)\n",
    "    self.ann = nn.Sequential(\n",
    "        nn.Linear(d_model, d_model * 4),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(d_model * 4, d_model),\n",
    "        nn.Dropout(dropout_prob),\n",
    "    )\n",
    "    self.dropout = nn.Dropout(p=dropout_prob)\n",
    "  \n",
    "  def forward(self, x, pad_mask=None):\n",
    "    x = self.ln1(x + self.mha(x, x, x, pad_mask))\n",
    "    x = self.ln2(x + self.ann(x))\n",
    "    x = self.dropout(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b7ef03-601f-438a-ae43-fe5fd05c4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "  def __init__(self, d_k, d_model, n_heads, max_len, dropout_prob=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.ln1 = nn.LayerNorm(d_model)\n",
    "    self.ln2 = nn.LayerNorm(d_model)\n",
    "    self.ln3 = nn.LayerNorm(d_model)\n",
    "    self.mha1 = MultiHeadAttention(d_k, d_model, n_heads, max_len, causal=True)\n",
    "    self.mha2 = MultiHeadAttention(d_k, d_model, n_heads, max_len, causal=False)\n",
    "    self.ann = nn.Sequential(\n",
    "        nn.Linear(d_model, d_model * 4),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(d_model * 4, d_model),\n",
    "        nn.Dropout(dropout_prob),\n",
    "    )\n",
    "    self.dropout = nn.Dropout(p=dropout_prob)\n",
    "  \n",
    "  def forward(self, enc_output, dec_input, enc_mask=None, dec_mask=None):\n",
    "    # self-attention on decoder input\n",
    "    x = self.ln1(\n",
    "        dec_input + self.mha1(dec_input, dec_input, dec_input, dec_mask))\n",
    "\n",
    "    # multi-head attention including encoder output\n",
    "    x = self.ln2(x + self.mha2(x, enc_output, enc_output, enc_mask))\n",
    "\n",
    "    x = self.ln3(x + self.ann(x))\n",
    "    x = self.dropout(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fa7560-248b-482d-b861-b6e4439cf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "  def __init__(self, d_model, max_len=2048, dropout_prob=0.1):\n",
    "    super().__init__()\n",
    "    self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    position = torch.arange(max_len).unsqueeze(1)\n",
    "    exp_term = torch.arange(0, d_model, 2)\n",
    "    div_term = torch.exp(exp_term * (-math.log(10000.0) / d_model))\n",
    "    pe = torch.zeros(1, max_len, d_model)\n",
    "    pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "    pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "    self.register_buffer('pe', pe)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x.shape: N x T x D\n",
    "    x = x + self.pe[:, :x.size(1), :]\n",
    "    return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54a4021-3696-4df0-a8da-4facc2e346e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               max_len,\n",
    "               d_k,\n",
    "               d_model,\n",
    "               n_heads,\n",
    "               n_layers,\n",
    "              #  n_classes,\n",
    "               dropout_prob):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    self.pos_encoding = PositionalEncoding(d_model, max_len, dropout_prob)\n",
    "    transformer_blocks = [\n",
    "        EncoderBlock(\n",
    "            d_k,\n",
    "            d_model,\n",
    "            n_heads,\n",
    "            max_len,\n",
    "            dropout_prob) for _ in range(n_layers)]\n",
    "    self.transformer_blocks = nn.Sequential(*transformer_blocks)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "    # self.fc = nn.Linear(d_model, n_classes)\n",
    "  \n",
    "  def forward(self, x, pad_mask=None):\n",
    "    x = self.embedding(x)\n",
    "    x = self.pos_encoding(x)\n",
    "    for block in self.transformer_blocks:\n",
    "      x = block(x, pad_mask)\n",
    "\n",
    "    # many-to-one (x has the shape N x T x D)\n",
    "    # x = x[:, 0, :]\n",
    "\n",
    "    x = self.ln(x)\n",
    "    # x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b415358-bb31-403b-9519-8702e7b7259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               max_len,\n",
    "               d_k,\n",
    "               d_model,\n",
    "               n_heads,\n",
    "               n_layers,\n",
    "               dropout_prob):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    self.pos_encoding = PositionalEncoding(d_model, max_len, dropout_prob)\n",
    "    transformer_blocks = [\n",
    "        DecoderBlock(\n",
    "            d_k,\n",
    "            d_model,\n",
    "            n_heads,\n",
    "            max_len,\n",
    "            dropout_prob) for _ in range(n_layers)]\n",
    "    self.transformer_blocks = nn.Sequential(*transformer_blocks)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "    self.fc = nn.Linear(d_model, vocab_size)\n",
    "  \n",
    "  def forward(self, enc_output, dec_input, enc_mask=None, dec_mask=None):\n",
    "    x = self.embedding(dec_input)\n",
    "    x = self.pos_encoding(x)\n",
    "    for block in self.transformer_blocks:\n",
    "      x = block(enc_output, x, enc_mask, dec_mask)\n",
    "    x = self.ln(x)\n",
    "    x = self.fc(x) # many-to-many\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa56edb1-8302-4066-bdea-3531a5b37059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "  \n",
    "  def forward(self, enc_input, dec_input, enc_mask, dec_mask):\n",
    "    enc_output = self.encoder(enc_input, enc_mask)\n",
    "    dec_output = self.decoder(enc_output, dec_input, enc_mask, dec_mask)\n",
    "    return dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2769a088-9400-42d5-b7d9-e827372f56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "encoder = Encoder(vocab_size=20_000,\n",
    "                  max_len=512,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "decoder = Decoder(vocab_size=10_000,\n",
    "                  max_len=512,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "transformer = Transformer(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c886d7-c7bc-4566-948a-6bf2c7f478b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(10000, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mha2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mha2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0683e1f-f6b6-4229-8694-383250ca2491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 10000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xe = np.random.randint(0, 20_000, size=(8, 512))\n",
    "xe_t = torch.tensor(xe).to(device)\n",
    "\n",
    "xd = np.random.randint(0, 10_000, size=(8, 256))\n",
    "xd_t = torch.tensor(xd).to(device)\n",
    "\n",
    "maske = np.ones((8, 512))\n",
    "maske[:, 256:] = 0\n",
    "maske_t = torch.tensor(maske).to(device)\n",
    "\n",
    "maskd = np.ones((8, 256))\n",
    "maskd[:, 128:] = 0\n",
    "maskd_t = torch.tensor(maskd).to(device)\n",
    "\n",
    "out = transformer(xe_t, xd_t, maske_t, maskd_t)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e4f134-ca6e-4bec-b543-42b59bdd21ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3914,  0.3828, -0.2511,  ..., -0.2705,  0.8348, -0.5598],\n",
       "         [-0.3135,  0.7051,  0.7541,  ...,  0.7199, -0.1306, -0.3908],\n",
       "         [ 0.3546,  0.1359,  0.2511,  ..., -0.2765, -0.7948, -0.1945],\n",
       "         ...,\n",
       "         [ 0.8060,  0.4446,  0.1537,  ...,  0.4130, -0.6083, -0.8568],\n",
       "         [-0.2599,  0.6027, -0.3151,  ..., -0.7219, -0.7060,  0.3909],\n",
       "         [-0.2150,  0.0981,  0.3805,  ..., -1.0750,  0.0791,  1.3998]],\n",
       "\n",
       "        [[-0.4979,  0.7351,  1.0207,  ..., -0.1121, -0.2521, -0.6900],\n",
       "         [ 0.2643,  0.0913,  0.2036,  ..., -0.6727,  1.1273, -0.1900],\n",
       "         [-0.4759,  1.0101, -0.2528,  ...,  0.5787,  1.3416,  0.2369],\n",
       "         ...,\n",
       "         [ 0.0579, -0.0446,  0.3272,  ..., -0.9375, -0.4254,  1.2658],\n",
       "         [-1.3184, -0.2041, -0.6116,  ..., -0.6374,  0.5771,  0.0363],\n",
       "         [ 0.1065, -0.0060, -0.6841,  ..., -0.3576,  0.8211,  0.7918]],\n",
       "\n",
       "        [[ 0.5741,  0.8217,  0.3460,  ...,  0.3691, -0.3229, -0.1528],\n",
       "         [ 0.5799,  0.9119, -0.8218,  ...,  0.3326,  0.4002, -0.0925],\n",
       "         [ 0.2262,  0.7077,  1.4977,  ..., -0.1485, -1.1130, -0.1887],\n",
       "         ...,\n",
       "         [-0.7413,  0.1162,  0.7189,  ..., -0.8227, -0.0758, -0.2751],\n",
       "         [ 0.1396,  0.4573, -0.6593,  ..., -0.7223,  0.5253, -0.3217],\n",
       "         [-0.2057,  0.6139,  0.7147,  ..., -0.4377, -0.4331,  0.7370]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1030,  1.1077,  1.2567,  ..., -0.4738,  0.8898, -0.1402],\n",
       "         [-0.4285,  1.2820,  0.9798,  ...,  0.1420,  0.5386,  1.5668],\n",
       "         [ 0.2085,  1.5723,  0.6604,  ...,  0.9349, -0.3116,  0.1676],\n",
       "         ...,\n",
       "         [-1.1432, -0.4005, -0.6414,  ..., -0.6782,  1.0720,  0.5056],\n",
       "         [-0.0293,  0.1530, -0.4477,  ..., -0.8123, -1.1282, -0.1363],\n",
       "         [-0.5422, -0.5201,  0.5616,  ..., -1.1830, -0.1971,  0.0088]],\n",
       "\n",
       "        [[ 0.5900,  1.3144,  0.4662,  ...,  1.0728,  1.1810,  0.8285],\n",
       "         [ 0.3452,  0.1729,  1.8909,  ...,  0.4041, -1.1729, -0.2243],\n",
       "         [ 0.6972,  0.7481, -0.1910,  ...,  1.7474,  0.1394, -0.8165],\n",
       "         ...,\n",
       "         [-0.4801,  0.4462, -0.0484,  ..., -1.0036,  0.0206,  0.7239],\n",
       "         [-0.7620, -0.4706, -0.2023,  ..., -0.5876,  0.2842, -0.0394],\n",
       "         [ 0.1787, -0.0774,  0.7681,  ..., -0.8563,  0.2510,  0.7515]],\n",
       "\n",
       "        [[-0.1977,  0.9775,  1.2769,  ...,  0.3207, -0.8548,  0.5638],\n",
       "         [-0.1450, -0.0046, -0.0920,  ...,  0.5217,  0.3242,  0.8761],\n",
       "         [ 0.4575,  1.1692,  0.6631,  ...,  0.5994, -0.3423, -0.2204],\n",
       "         ...,\n",
       "         [-0.0247, -0.7386, -0.6670,  ...,  0.2930,  0.5593,  0.4721],\n",
       "         [-0.6765,  0.9534,  0.2168,  ..., -0.4142, -0.0231, -0.4496],\n",
       "         [-0.5632, -0.1236,  0.0148,  ..., -1.0241, -0.0467,  0.6054]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1203615-6d8c-4cc4-a9a3-b060860a0268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Go.\tVe.\n",
      "2:Go.\tVete.\n",
      "3:Go.\tVaya.\n",
      "4:Hi.\tHola.\n",
      "5:Run!\tÂ¡Corre!\n",
      "6:Who?\tÂ¿QuiÃ©n?\n",
      "7:Wow!\tÂ¡Ã“rale!\n",
      "8:Fire!\tÂ¡Fuego!\n",
      "9:Fire!\tÂ¡Incendio!\n"
     ]
    }
   ],
   "source": [
    "# !head spa.txt\n",
    "!findstr /n \".\" ..\\spa.txt | findstr \"^.:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d412576d-4815-4852-9dd5-375a6ea50e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corre!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1\n",
       "0   Go.      Ve.\n",
       "1   Go.    Vete.\n",
       "2   Go.    Vaya.\n",
       "3   Hi.    Hola.\n",
       "4  Run!  ¡Corre!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('..\\spa.txt', sep=\"\\t\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c689562-4b75-466d-88b2-ca0b4a9f17a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115245, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e83d993c-99d5-4990-b21f-3f3f299dfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:30_000] # takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7bbe723-4fc6-4557-94c7-9e36fd80b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['en', 'es']\n",
    "df.to_csv('..\\spa.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2977b026-9009-4a8b-9195-24387ec2add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:en,es\n",
      "2:Go.,Ve.\n",
      "3:Go.,Vete.\n",
      "4:Go.,Vaya.\n",
      "5:Hi.,Hola.\n",
      "6:Run!,Â¡Corre!\n",
      "7:Who?,Â¿QuiÃ©n?\n",
      "8:Wow!,Â¡Ã“rale!\n",
      "9:Fire!,Â¡Fuego!\n"
     ]
    }
   ],
   "source": [
    "#!head spa.csv\n",
    "!findstr /n \".\" ..\\spa.csv | findstr \"^.:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dc3d6aa-78dc-415f-9b52-844c8801634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a671d57f-d9ab-46ab-82a7-b7862f959aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/sthor/.cache/huggingface/datasets/csv/default-6b3d3956e35e7301/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/sthor/.cache/huggingface/datasets/csv/default-6b3d3956e35e7301/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 500.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset('csv', data_files='..\\spa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21356ba3-d6e7-4e94-b55a-354fe5b98325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'es'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "926da42d-8035-4ff6-8ef4-deb8340a360a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'es'],\n",
       "        num_rows: 21000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'es'],\n",
       "        num_rows: 9000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = raw_dataset['train'].train_test_split(test_size=0.3, seed=42)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa4bbeb-2315-47a0-9b1e-e004aea3e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55eb3a36-96ae-4a9c-813c-3b2a379a7e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Yo', '▁puedo', '▁arreglarlo', '.', '</s>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sentence = split[\"train\"][0][\"en\"]\n",
    "es_sentence = split[\"train\"][0][\"es\"]\n",
    "\n",
    "inputs = tokenizer(en_sentence)\n",
    "targets = tokenizer(text_target=es_sentence)\n",
    "\n",
    "tokenizer.convert_ids_to_tokens(targets['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f7d477e-c49e-4bfb-8406-25ea82cbcf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yo puedo arreglarlo.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "738eaadf-de94-4fce-a844-9dcb328dc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch['en'], max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    labels = tokenizer(\n",
    "        text_target=batch['es'], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "343b7352-890b-45a6-b8ca-fee407573c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = split.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7a8e5ae-381a-4211-8e1f-51b0f919e3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b4fcd0d-022b-4e2e-8cff-95363645106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e971b2e-5cce-4e9b-9298-43e57514e426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(0, 5)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "279a445f-d57e-42ad-beb5-cc7b3cc75f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   33,    88,  9222,    48,     3,     0, 65000, 65000],\n",
       "        [  552, 11490,     9,   310,   255,     3,     0, 65000],\n",
       "        [  143,    31,   125,  1208,     3,     0, 65000, 65000],\n",
       "        [ 1093,   220,  1890,    23,    48,     3,     0, 65000],\n",
       "        [  124,    20,   100, 18422,    48,   141,     3,     0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b019cff-07b8-469a-8da4-f1f1e08b6b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8223964-633a-4ae4-af79-610b2b91e2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  711,  1039, 44159,     3,     0,  -100,  -100,  -100],\n",
       "        [ 2722, 18663,   239,   212,     3,     0,  -100,  -100],\n",
       "        [  539,    43,   155,   960,     3,     0,  -100,  -100],\n",
       "        [15165,  1250,   380,  3564,    36,  1016,     3,     0],\n",
       "        [  350,     8, 19153,    29, 31326,     3,     0,  -100]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaec1466-bbeb-4712-a19a-586b9c6fffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 65000]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "434f851f-15e6-4ccd-b66f-6292674f0335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', '<unk>', '<pad>']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91e37f11-867f-4f58-a7a9-13733593c013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [65000, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b356cf60-716e-417c-bbaf-1114b13fcc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c7248f9-4eb5-4814-8560-f77124f27fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: input_ids v.shape: torch.Size([32, 8])\n",
      "k: attention_mask v.shape: torch.Size([32, 8])\n",
      "k: labels v.shape: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# check how it works\n",
    "for batch in train_loader:\n",
    "  for k, v in batch.items():\n",
    "    print(\"k:\", k, \"v.shape:\", v.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c1e7388-2a10-4994-8260-5774f38f1590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65001"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0fdc2fd-7073-47e6-80e0-a5d7cf73d306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ѕэр'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4940a3fc-a024-4a16-8ae3-a7cff027e2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"cls_token\": \"<s>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a8bb48e-56f9-4240-9206-8c6f8fe60446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [65001, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1068bfa2-2941-4102-bfd9-66c398482a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65001"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cc2770c-be50-45d9-9789-9fad2531cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size=tokenizer.vocab_size + 1,\n",
    "                  max_len=512,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "decoder = Decoder(vocab_size=tokenizer.vocab_size + 1,\n",
    "                  max_len=512,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "transformer = Transformer(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01771f38-0104-475b-8cb9-c6c3bf4bb865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(65002, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mha2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mha2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=65002, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7498327-7583-421c-8f29-af0877192c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.Adam(transformer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f13bc0d-d085-471e-8347-e356813fe12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# A function to encapsulate the training loop\n",
    "def train(model, criterion, optimizer, train_loader, valid_loader, epochs):\n",
    "  train_losses = np.zeros(epochs)\n",
    "  test_losses = np.zeros(epochs)\n",
    "\n",
    "  for it in range(epochs):\n",
    "    model.train()\n",
    "    t0 = datetime.now()\n",
    "    train_loss = []\n",
    "    for batch in train_loader:\n",
    "      # move data to GPU (enc_input, enc_mask, translation)\n",
    "      batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      enc_input = batch['input_ids']\n",
    "      enc_mask = batch['attention_mask']\n",
    "      targets = batch['labels']\n",
    "\n",
    "      # shift targets forwards to get decoder_input\n",
    "      dec_input = targets.clone().detach()\n",
    "      dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "      dec_input[:, 0] = 65_001\n",
    "\n",
    "      # also convert all -100 to pad token id\n",
    "      dec_input = dec_input.masked_fill(\n",
    "          dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "      # make decoder input mask\n",
    "      dec_mask = torch.ones_like(dec_input)\n",
    "      dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "      loss = criterion(outputs.transpose(2, 1), targets)\n",
    "        \n",
    "      # Backward and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss.append(loss.item())\n",
    "\n",
    "    # Get train loss and test loss\n",
    "    train_loss = np.mean(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    for batch in valid_loader:\n",
    "      batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "      enc_input = batch['input_ids']\n",
    "      enc_mask = batch['attention_mask']\n",
    "      targets = batch['labels']\n",
    "\n",
    "      # shift targets forwards to get decoder_input\n",
    "      dec_input = targets.clone().detach()\n",
    "      dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "      dec_input[:, 0] = 65_001\n",
    "\n",
    "      # change -100s to regular padding\n",
    "      dec_input = dec_input.masked_fill(\n",
    "          dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "      # make decoder input mask\n",
    "      dec_mask = torch.ones_like(dec_input)\n",
    "      dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "      outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "      loss = criterion(outputs.transpose(2, 1), targets)\n",
    "      test_loss.append(loss.item())\n",
    "    test_loss = np.mean(test_loss)\n",
    "\n",
    "    # Save losses\n",
    "    train_losses[it] = train_loss\n",
    "    test_losses[it] = test_loss\n",
    "    \n",
    "    dt = datetime.now() - t0\n",
    "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "      Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "  \n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6015be9f-8991-4eef-9793-23d9e68d4449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 4.8764,       Test Loss: 3.8785, Duration: 0:00:19.162735\n",
      "Epoch 2/15, Train Loss: 3.5432,       Test Loss: 3.4034, Duration: 0:00:17.596072\n",
      "Epoch 3/15, Train Loss: 3.0743,       Test Loss: 3.0690, Duration: 0:00:18.493645\n",
      "Epoch 4/15, Train Loss: 2.7185,       Test Loss: 2.8442, Duration: 0:00:18.775064\n",
      "Epoch 5/15, Train Loss: 2.4321,       Test Loss: 2.6897, Duration: 0:00:17.865572\n",
      "Epoch 6/15, Train Loss: 2.1912,       Test Loss: 2.5760, Duration: 0:00:17.512485\n",
      "Epoch 7/15, Train Loss: 1.9975,       Test Loss: 2.4892, Duration: 0:00:17.866828\n",
      "Epoch 8/15, Train Loss: 1.8330,       Test Loss: 2.4430, Duration: 0:00:17.252428\n",
      "Epoch 9/15, Train Loss: 1.7062,       Test Loss: 2.4003, Duration: 0:00:16.956122\n",
      "Epoch 10/15, Train Loss: 1.5915,       Test Loss: 2.3981, Duration: 0:00:17.164544\n",
      "Epoch 11/15, Train Loss: 1.4977,       Test Loss: 2.3858, Duration: 0:00:17.336035\n",
      "Epoch 12/15, Train Loss: 1.4174,       Test Loss: 2.3810, Duration: 0:00:17.180671\n",
      "Epoch 13/15, Train Loss: 1.3509,       Test Loss: 2.3807, Duration: 0:00:19.634777\n",
      "Epoch 14/15, Train Loss: 1.2900,       Test Loss: 2.3883, Duration: 0:00:19.477567\n",
      "Epoch 15/15, Train Loss: 1.2394,       Test Loss: 2.3971, Duration: 0:00:19.398175\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = train(\n",
    "    transformer, criterion, optimizer, train_loader, valid_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5c023e7-affc-4891-8d1d-d8d5057467af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can I take a day off?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it out\n",
    "\n",
    "input_sentence = split['test'][10]['en']\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cf05932-f7d9-49ad-b868-10278ee42e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1283,   33,  273,    8,  502,  843,   21,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input = tokenizer(input_sentence, return_tensors='pt')\n",
    "enc_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9ec0f93-5355-462d-896d-960ea199d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[65001,     0]]), 'attention_mask': tensor([[1, 1]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input_str = '<s>'\n",
    "\n",
    "dec_input = tokenizer(text_target=dec_input_str, return_tensors='pt')\n",
    "dec_input\n",
    "\n",
    "# We'll ignore the final 0 ( </s> )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c898506c-ecfa-4d4a-a7a4-d9ff12c2a6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4422, -6.4526,  4.3074,  ..., -6.0870, -7.3968, -4.3901]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input.to(device)\n",
    "dec_input.to(device)\n",
    "output = transformer(\n",
    "    enc_input['input_ids'],\n",
    "    dec_input['input_ids'][:, :-1],\n",
    "    enc_input['attention_mask'],\n",
    "    dec_input['attention_mask'][:, :-1],\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30a421d8-b6d9-4e92-ae00-442a5cfb1520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 65002])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape # N x T x V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e85b083-90ba-43dc-a77f-ce4f39851f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 64])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output = encoder(enc_input['input_ids'], enc_input['attention_mask'])\n",
    "enc_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2feea52-7b98-4265-a1b3-7b65c4719dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 65002])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output = decoder(\n",
    "    enc_output,\n",
    "    dec_input['input_ids'][:, :-1],\n",
    "    enc_input['attention_mask'],\n",
    "    dec_input['attention_mask'][:, :-1],\n",
    ")\n",
    "dec_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "079c1c90-9f74-469b-bd54-165faf4dbe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(output, dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ccd68d0e-bfea-4272-8a01-3047f98351d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_input_ids = dec_input['input_ids'][:, :-1]\n",
    "dec_attn_mask = dec_input['attention_mask'][:, :-1]\n",
    "\n",
    "for _ in range(32):\n",
    "  dec_output = decoder(\n",
    "      enc_output,\n",
    "      dec_input_ids,\n",
    "      enc_input['attention_mask'],\n",
    "      dec_attn_mask,\n",
    "  )\n",
    "\n",
    "  # choose the best value (or sample)\n",
    "  prediction_id = torch.argmax(dec_output[:, -1, :], axis=-1)\n",
    "\n",
    "  # append to decoder input\n",
    "  dec_input_ids = torch.hstack((dec_input_ids, prediction_id.view(1, 1)))\n",
    "\n",
    "  # recreate mask\n",
    "  dec_attn_mask = torch.ones_like(dec_input_ids)\n",
    "\n",
    "  # exit when reach </s>\n",
    "  if prediction_id == 0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea7bfc99-4a1f-4de2-a383-a965d2d13874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ¿Puedo traer puesto un día?</s>'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dec_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04d45c29-7596-4ffc-b282-a40e78cd0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿Puedo tomarme un día libre?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split['test'][10]['es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af1f2d5e-7e55-49c5-a1dd-04061761bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence):\n",
    "  # get encoder output first\n",
    "  enc_input = tokenizer(input_sentence, return_tensors='pt').to(device)\n",
    "  enc_output = encoder(enc_input['input_ids'], enc_input['attention_mask'])\n",
    "\n",
    "  # setup initial decoder input\n",
    "  dec_input_ids = torch.tensor([[65_001]], device=device)\n",
    "  dec_attn_mask = torch.ones_like(dec_input_ids, device=device)\n",
    "\n",
    "  # now do the decoder loop\n",
    "  for _ in range(32):\n",
    "    dec_output = decoder(\n",
    "        enc_output,\n",
    "        dec_input_ids,\n",
    "        enc_input['attention_mask'],\n",
    "        dec_attn_mask,\n",
    "    )\n",
    "\n",
    "    # choose the best value (or sample)\n",
    "    prediction_id = torch.argmax(dec_output[:, -1, :], axis=-1)\n",
    "\n",
    "    # append to decoder input\n",
    "    dec_input_ids = torch.hstack((dec_input_ids, prediction_id.view(1, 1)))\n",
    "\n",
    "    # recreate mask\n",
    "    dec_attn_mask = torch.ones_like(dec_input_ids)\n",
    "\n",
    "    # exit when reach </s>\n",
    "    if prediction_id == 0:\n",
    "      break\n",
    "  \n",
    "  translation = tokenizer.decode(dec_input_ids[0, 1:])\n",
    "  print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8acea216-9301-4f37-b3bb-1c9c88304608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cómo estás?</s>\n"
     ]
    }
   ],
   "source": [
    "translate(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f067a-56f2-413e-9145-4a6957fa1637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
