{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c66fed2-ae33-4631-a867-72bac4405345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c7b4ca-28c4-47ef-8195-3bce858bf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line.rstrip() for line in open(\"robert_frost.txt\")]\n",
    "lines = [line for line in lines if len(line) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2c35a5-b101-4f4f-91cc-2573b2fe1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two roads diverged in a yellow wood,',\n",
       " 'And sorry I could not travel both',\n",
       " 'And be one traveler, long I stood',\n",
       " 'And looked down one as far as I could',\n",
       " 'To where it bent in the undergrowth;',\n",
       " 'Then took the other, as just as fair,',\n",
       " 'And having perhaps the better claim',\n",
       " 'Because it was grassy and wanted wear,',\n",
       " 'Though as for that the passing there',\n",
       " 'Had worn them really about the same,']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020b4da3-d6b3-4dc9-bffe-7774f216fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading pytorch_model.bin: 100%|██████████| 548M/548M [01:21<00:00, 6.72MB/s] \n",
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sthor\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "gen = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af22ae9-3b05-495b-b00d-5daf44eaeff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227f81fb-76ad-4ef2-b43b-cfbd16b72a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two roads diverged in a yellow wood,'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a3db92-217d-42f3-8f48-457c89d058e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation\\utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Two roads diverged in a yellow wood, while the road in a white puddle was a complete blue on account of the rain coming in. It had been raining outside for some time, so it hadn't taken long for people on both sides of\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fff259f-83b4-44a7-95ef-805beb76b023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, while the road in a '\n",
      "                    'white puddle was a complete blue on account of the rain '\n",
      "                    'coming in. It had been raining outside for some time, so '\n",
      "                    \"it hadn't taken long for people on both sides of\"}]\n"
     ]
    }
   ],
   "source": [
    "pprint(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f09c30-f82a-42b9-ac9c-d1a7c2b3fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, some of the highways '\n",
      "                    'carrying cars had lights that lit up'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(gen(lines[0], max_length = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a2e7ef1-d728-4ae5-82a7-225bbd54cf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, where someone threw '\n",
      "                    'a stone at the front passenger door,'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, with three different '\n",
      "                    'ways to cross the bridge, including three'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, but the main lanes '\n",
      "                    'were cleared and no one in the'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(gen(lines[0], num_return_sequences = 3, max_length = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed2195d-f450-4283-bc13-eb53193abb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace = False, fix_sentence_endings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c518ab-67df-4a65-9dfd-62ea0b86eb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood, including one that blocked the\n",
      "road leading to another intersection in the middle of the city.  The\n",
      "cars that were\n"
     ]
    }
   ],
   "source": [
    "out = gen(lines[0], max_length = 30)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71650267-4ec2-4f47-a7ff-a938327f26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = 'Two roads diverged in a yellow wood, including one that blocked the road leading to another intersection in the middle of the city.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d02e553a-ad1c-4545-ad8c-2f6d0ccdf4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood, including one that blocked the\n",
      "road leading to another intersection in the middle of the city.\n",
      "And be\n",
      "one traveler, long I stood, until I was nearly in a panic when I\n",
      "spotted it, passing another sign, that read: \"Laws for car\n"
     ]
    }
   ],
   "source": [
    "out = gen(prev + \"\\n\" + lines[2], max_length = 60)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c88a2a07-106a-4a61-9dcb-2ebac4407cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = \"Two roads diverged in a yellow wood, including one that blocked the\" +\\\n",
    "\"road leading to another intersection in the middle of the city.\" +\\\n",
    "\"And be\" +\\\n",
    "\"one traveler, long I stood, until I was nearly in a panic when I\" +\\\n",
    "\"spotted it, passing another sign, that read: 'Laws for car'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab45feeb-f651-46e0-b62a-b104efcd54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood, including one that blocked\n",
      "theroad leading to another intersection in the middle of the city.And\n",
      "beone traveler, long I stood, until I was nearly in a panic when\n",
      "Ispotted it, passing another sign, that read: 'Laws for car'\n",
      "To where\n",
      "it bent in the undergrowth; and which had been placed in the centre,\n",
      "next to that road.  Here it ran again;\n"
     ]
    }
   ],
   "source": [
    "out = gen(prev + \"\\n\" + lines[4], max_length = 90)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76a5a97a-3a48-4334-a162-439aef634078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: think of ways you'd apply GPT-2 and text generation in the real\n",
    "# world and as a business / startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e23ffa-1dc5-431d-a280-1c4934183c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Neural networks whith attention have been used with great success\" +\\\n",
    "\" in natural language processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22bb2c45-e94f-4c37-83ad-dd2a1bc2da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural networks whith attention have been used with great success in\n",
      "natural language processing and in machine learning.\n",
      "\n",
      "We've been\n",
      "conducting deep learning of all sorts, with very few details.  There\n",
      "will always be some questions or clues that need to be investigated.\n",
      "We'll probably discover new things that we may have ignored in\n",
      "previous work.\n",
      "\n",
      "When we start from the beginning point of it all,\n",
      "we'll be talking to us, at least once, about the idea of using deep\n",
      "learning to find the answer.  And we'll be able to demonstrate that\n",
      "deep learning in the most efficient way.\n",
      "\n",
      "The point is that we have\n",
      "some clues in our brain networks, and if we understand them better,\n",
      "we'll be able to be less dependent on conventional brain networks, and\n",
      "if using our brain data, we can begin to see whether they are capable\n",
      "of discovering interesting connections.  And if we start talking about\n",
      "using Deep Learning in a better way, we can also start discussing some\n",
      "of that evidence, particularly the idea of learning an image or seeing\n",
      "an image when we have some visual information, and maybe even using a\n",
      "map of the city.\n",
      "\n",
      "One of the things about using Deep Learning for\n",
      "information processing is that it only accepts data at a moment's\n",
      "notice.  We can't control how we learn or how we use it.  In fact,\n",
      "Deep Learning can only take information at the moments when it is\n",
      "needed most.\n",
      "\n",
      "We have the ability to do things at a very early scale\n",
      "in the brain\n"
     ]
    }
   ],
   "source": [
    "out = gen(prompt, max_length=300)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1fd052e-cc45-4cb4-920e-63411409bf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff7bbda8-7e0b-4498-9482-489c37a2c73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "gen = pipeline(\"text-generation\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72f59932-9ba9-49d0-b682-e28180608fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Neural networks whith attention have been used with great success\" +\\\n",
    "\" in natural language processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94624c55-939f-46c4-bb69-ae05a36de5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sthor\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation\\utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural networks whith attention have been used with great success in\n",
      "natural language processing [15]. Because of the limited range\n",
      "required to achieve this, a number of approaches have been undertaken.\n",
      "First, the researchers examined whether they can efficiently extract\n",
      "neural activity using the attention-to-mind (NSTM) method.  This\n",
      "method is a novel neural model (e.g., [16]). Then, they used a\n",
      "technique called a multi-channel (LPK) approach to probe neural\n",
      "activity.  This approach includes a series of simple, simultaneous\n",
      "(single input) commands.  When a single-channel activity request is\n",
      "made, a second input control (also called \"task activation strategy\")\n",
      "is used to activate it.  Here, a second input task is performed to\n",
      "assess whether an auditory stimulus (either in the foreground of the\n",
      "current activity or an adjacent space) elicits a task in the\n",
      "background.  In the main, this task comprises 3 pre-specified inputs\n",
      "to a single network [1]. Each input command is divided into 2 separate\n",
      "blocks in an ordered fashion within 1:1 time-point.  Thus, a task can\n",
      "be implemented as an array of distinct blocks of inputs.  In a recent\n",
      "study by the same team (Mazhin et al., 2007), two different types of\n",
      "interrelated-input tasks were used to extract neural activity [11].\n",
      "These tasks contain different pre-specified targets that activate the\n",
      "task in separate blocks: 1) stimulus inputs and 2) target inputs (3).\n",
      "The tasks are\n"
     ]
    }
   ],
   "source": [
    "out = gen(prompt, max_length=300)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479ba6a-629c-40a6-b035-59b9586f4623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
